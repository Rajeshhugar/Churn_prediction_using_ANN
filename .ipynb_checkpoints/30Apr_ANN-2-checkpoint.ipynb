{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "djsxuqEDyqwY",
    "outputId": "93d26282-1807-4d97-b9a1-7d32acbf0d03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep 25 07:24:18 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   53C    P8    13W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j9CW9dlIytgS",
    "outputId": "0923cb6a-c9cb-4524-9151-31cb530de39f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version\n",
      "----------------------------- ----------------------------\n",
      "absl-py                       1.2.0\n",
      "aeppl                         0.0.33\n",
      "aesara                        2.7.9\n",
      "aiohttp                       3.8.1\n",
      "aiosignal                     1.2.0\n",
      "alabaster                     0.7.12\n",
      "albumentations                1.2.1\n",
      "altair                        4.2.0\n",
      "appdirs                       1.4.4\n",
      "arviz                         0.12.1\n",
      "astor                         0.8.1\n",
      "astropy                       4.3.1\n",
      "astunparse                    1.6.3\n",
      "async-timeout                 4.0.2\n",
      "asynctest                     0.13.0\n",
      "atari-py                      0.2.9\n",
      "atomicwrites                  1.4.1\n",
      "attrs                         22.1.0\n",
      "audioread                     3.0.0\n",
      "autograd                      1.4\n",
      "Babel                         2.10.3\n",
      "backcall                      0.2.0\n",
      "beautifulsoup4                4.6.3\n",
      "bleach                        5.0.1\n",
      "blis                          0.7.8\n",
      "bokeh                         2.3.3\n",
      "branca                        0.5.0\n",
      "bs4                           0.0.1\n",
      "CacheControl                  0.12.11\n",
      "cached-property               1.5.2\n",
      "cachetools                    4.2.4\n",
      "catalogue                     2.0.8\n",
      "certifi                       2022.6.15\n",
      "cffi                          1.15.1\n",
      "cftime                        1.6.1\n",
      "chardet                       3.0.4\n",
      "charset-normalizer            2.1.1\n",
      "click                         7.1.2\n",
      "clikit                        0.6.2\n",
      "cloudpickle                   1.5.0\n",
      "cmake                         3.22.6\n",
      "cmdstanpy                     1.0.7\n",
      "colorcet                      3.0.0\n",
      "colorlover                    0.3.0\n",
      "community                     1.0.0b1\n",
      "cons                          0.4.5\n",
      "contextlib2                   0.5.5\n",
      "convertdate                   2.4.0\n",
      "crashtest                     0.3.1\n",
      "crcmod                        1.7\n",
      "cufflinks                     0.17.3\n",
      "cupy-cuda111                  9.4.0\n",
      "cvxopt                        1.3.0\n",
      "cvxpy                         1.2.1\n",
      "cycler                        0.11.0\n",
      "cymem                         2.0.6\n",
      "Cython                        0.29.32\n",
      "daft                          0.0.4\n",
      "dask                          2022.2.0\n",
      "datascience                   0.17.5\n",
      "debugpy                       1.0.0\n",
      "decorator                     4.4.2\n",
      "defusedxml                    0.7.1\n",
      "descartes                     1.1.0\n",
      "dill                          0.3.5.1\n",
      "distributed                   2022.2.0\n",
      "dlib                          19.24.0\n",
      "dm-tree                       0.1.7\n",
      "docutils                      0.17.1\n",
      "dopamine-rl                   1.0.5\n",
      "earthengine-api               0.1.323\n",
      "easydict                      1.9\n",
      "ecos                          2.0.10\n",
      "editdistance                  0.5.3\n",
      "en-core-web-sm                3.4.0\n",
      "entrypoints                   0.4\n",
      "ephem                         4.1.3\n",
      "et-xmlfile                    1.1.0\n",
      "etils                         0.7.1\n",
      "etuples                       0.3.8\n",
      "fa2                           0.3.5\n",
      "fastai                        2.7.9\n",
      "fastcore                      1.5.25\n",
      "fastdownload                  0.0.7\n",
      "fastdtw                       0.3.4\n",
      "fastjsonschema                2.16.1\n",
      "fastprogress                  1.0.3\n",
      "fastrlock                     0.8\n",
      "feather-format                0.4.1\n",
      "filelock                      3.8.0\n",
      "firebase-admin                4.4.0\n",
      "fix-yahoo-finance             0.0.22\n",
      "Flask                         1.1.4\n",
      "flatbuffers                   2.0.7\n",
      "folium                        0.12.1.post1\n",
      "frozenlist                    1.3.1\n",
      "fsspec                        2022.8.2\n",
      "future                        0.16.0\n",
      "gast                          0.5.3\n",
      "GDAL                          2.2.2\n",
      "gdown                         4.4.0\n",
      "gensim                        3.6.0\n",
      "geographiclib                 1.52\n",
      "geopy                         1.17.0\n",
      "gin-config                    0.5.0\n",
      "glob2                         0.7\n",
      "google                        2.0.3\n",
      "google-api-core               1.31.6\n",
      "google-api-python-client      1.12.11\n",
      "google-auth                   1.35.0\n",
      "google-auth-httplib2          0.0.4\n",
      "google-auth-oauthlib          0.4.6\n",
      "google-cloud-bigquery         1.21.0\n",
      "google-cloud-bigquery-storage 1.1.2\n",
      "google-cloud-core             1.0.3\n",
      "google-cloud-datastore        1.8.0\n",
      "google-cloud-firestore        1.7.0\n",
      "google-cloud-language         1.2.0\n",
      "google-cloud-storage          1.18.1\n",
      "google-cloud-translate        1.5.0\n",
      "google-colab                  1.0.0\n",
      "google-pasta                  0.2.0\n",
      "google-resumable-media        0.4.1\n",
      "googleapis-common-protos      1.56.4\n",
      "googledrivedownloader         0.4\n",
      "graphviz                      0.10.1\n",
      "greenlet                      1.1.3\n",
      "grpcio                        1.48.1\n",
      "gspread                       3.4.2\n",
      "gspread-dataframe             3.0.8\n",
      "gym                           0.25.2\n",
      "gym-notices                   0.0.8\n",
      "h5py                          3.1.0\n",
      "HeapDict                      1.0.1\n",
      "hijri-converter               2.2.4\n",
      "holidays                      0.15\n",
      "holoviews                     1.14.9\n",
      "html5lib                      1.0.1\n",
      "httpimport                    0.5.18\n",
      "httplib2                      0.17.4\n",
      "httplib2shim                  0.0.3\n",
      "httpstan                      4.6.1\n",
      "humanize                      0.5.1\n",
      "hyperopt                      0.1.2\n",
      "idna                          2.10\n",
      "imageio                       2.9.0\n",
      "imagesize                     1.4.1\n",
      "imbalanced-learn              0.8.1\n",
      "imblearn                      0.0\n",
      "imgaug                        0.4.0\n",
      "importlib-metadata            4.12.0\n",
      "importlib-resources           5.9.0\n",
      "imutils                       0.5.4\n",
      "inflect                       2.1.0\n",
      "intel-openmp                  2022.1.0\n",
      "intervaltree                  2.1.0\n",
      "ipykernel                     5.3.4\n",
      "ipython                       7.9.0\n",
      "ipython-genutils              0.2.0\n",
      "ipython-sql                   0.3.9\n",
      "ipywidgets                    7.7.1\n",
      "itsdangerous                  1.1.0\n",
      "jax                           0.3.17\n",
      "jaxlib                        0.3.15+cuda11.cudnn805\n",
      "jieba                         0.42.1\n",
      "Jinja2                        2.11.3\n",
      "joblib                        1.1.0\n",
      "jpeg4py                       0.1.4\n",
      "jsonschema                    4.3.3\n",
      "jupyter-client                6.1.12\n",
      "jupyter-console               6.1.0\n",
      "jupyter-core                  4.11.1\n",
      "jupyterlab-widgets            3.0.3\n",
      "kaggle                        1.5.12\n",
      "kapre                         0.3.7\n",
      "keras                         2.8.0\n",
      "Keras-Preprocessing           1.1.2\n",
      "keras-vis                     0.4.1\n",
      "kiwisolver                    1.4.4\n",
      "korean-lunar-calendar         0.2.1\n",
      "langcodes                     3.3.0\n",
      "libclang                      14.0.6\n",
      "librosa                       0.8.1\n",
      "lightgbm                      2.2.3\n",
      "llvmlite                      0.39.1\n",
      "lmdb                          0.99\n",
      "locket                        1.0.0\n",
      "logical-unification           0.4.5\n",
      "LunarCalendar                 0.0.9\n",
      "lxml                          4.9.1\n",
      "Markdown                      3.4.1\n",
      "MarkupSafe                    2.0.1\n",
      "marshmallow                   3.17.1\n",
      "matplotlib                    3.2.2\n",
      "matplotlib-venn               0.11.7\n",
      "miniKanren                    1.0.3\n",
      "missingno                     0.5.1\n",
      "mistune                       0.8.4\n",
      "mizani                        0.7.3\n",
      "mkl                           2019.0\n",
      "mlxtend                       0.14.0\n",
      "more-itertools                8.14.0\n",
      "moviepy                       0.2.3.5\n",
      "mpmath                        1.2.1\n",
      "msgpack                       1.0.4\n",
      "multidict                     6.0.2\n",
      "multipledispatch              0.6.0\n",
      "multitasking                  0.0.11\n",
      "murmurhash                    1.0.8\n",
      "music21                       5.5.0\n",
      "natsort                       5.5.0\n",
      "nbconvert                     5.6.1\n",
      "nbformat                      5.4.0\n",
      "netCDF4                       1.6.0\n",
      "networkx                      2.6.3\n",
      "nibabel                       3.0.2\n",
      "nltk                          3.7\n",
      "notebook                      5.3.1\n",
      "numba                         0.56.2\n",
      "numexpr                       2.8.3\n",
      "numpy                         1.21.6\n",
      "oauth2client                  4.1.3\n",
      "oauthlib                      3.2.0\n",
      "okgrade                       0.4.3\n",
      "opencv-contrib-python         4.6.0.66\n",
      "opencv-python                 4.6.0.66\n",
      "opencv-python-headless        4.6.0.66\n",
      "openpyxl                      3.0.10\n",
      "opt-einsum                    3.3.0\n",
      "osqp                          0.6.2.post0\n",
      "packaging                     21.3\n",
      "palettable                    3.3.0\n",
      "pandas                        1.3.5\n",
      "pandas-datareader             0.9.0\n",
      "pandas-gbq                    0.13.3\n",
      "pandas-profiling              1.4.1\n",
      "pandocfilters                 1.5.0\n",
      "panel                         0.12.1\n",
      "param                         1.12.2\n",
      "parso                         0.8.3\n",
      "partd                         1.3.0\n",
      "pastel                        0.2.1\n",
      "pathlib                       1.0.1\n",
      "pathy                         0.6.2\n",
      "patsy                         0.5.2\n",
      "pep517                        0.13.0\n",
      "pexpect                       4.8.0\n",
      "pickleshare                   0.7.5\n",
      "Pillow                        7.1.2\n",
      "pip                           21.1.3\n",
      "pip-tools                     6.2.0\n",
      "plotly                        5.5.0\n",
      "plotnine                      0.8.0\n",
      "pluggy                        0.7.1\n",
      "pooch                         1.6.0\n",
      "portpicker                    1.3.9\n",
      "prefetch-generator            1.0.1\n",
      "preshed                       3.0.7\n",
      "prettytable                   3.4.1\n",
      "progressbar2                  3.38.0\n",
      "promise                       2.3\n",
      "prompt-toolkit                2.0.10\n",
      "prophet                       1.1\n",
      "protobuf                      3.17.3\n",
      "psutil                        5.4.8\n",
      "psycopg2                      2.9.3\n",
      "ptyprocess                    0.7.0\n",
      "py                            1.11.0\n",
      "pyarrow                       6.0.1\n",
      "pyasn1                        0.4.8\n",
      "pyasn1-modules                0.2.8\n",
      "pycocotools                   2.0.4\n",
      "pycparser                     2.21\n",
      "pyct                          0.4.8\n",
      "pydantic                      1.9.2\n",
      "pydata-google-auth            1.4.0\n",
      "pydot                         1.3.0\n",
      "pydot-ng                      2.0.0\n",
      "pydotplus                     2.0.2\n",
      "PyDrive                       1.3.1\n",
      "pyemd                         0.5.1\n",
      "pyerfa                        2.0.0.1\n",
      "Pygments                      2.6.1\n",
      "pygobject                     3.26.1\n",
      "pylev                         1.4.0\n",
      "pymc                          4.1.4\n",
      "PyMeeus                       0.5.11\n",
      "pymongo                       4.2.0\n",
      "pymystem3                     0.2.0\n",
      "PyOpenGL                      3.1.6\n",
      "pyparsing                     3.0.9\n",
      "pyrsistent                    0.18.1\n",
      "pysimdjson                    3.2.0\n",
      "pysndfile                     1.3.8\n",
      "PySocks                       1.7.1\n",
      "pystan                        3.3.0\n",
      "pytest                        3.6.4\n",
      "python-apt                    0.0.0\n",
      "python-chess                  0.23.11\n",
      "python-dateutil               2.8.2\n",
      "python-louvain                0.16\n",
      "python-slugify                6.1.2\n",
      "python-utils                  3.3.3\n",
      "pytz                          2022.2.1\n",
      "pyviz-comms                   2.2.1\n",
      "PyWavelets                    1.3.0\n",
      "PyYAML                        6.0\n",
      "pyzmq                         23.2.1\n",
      "qdldl                         0.1.5.post2\n",
      "qudida                        0.0.4\n",
      "regex                         2022.6.2\n",
      "requests                      2.23.0\n",
      "requests-oauthlib             1.3.1\n",
      "resampy                       0.4.0\n",
      "rpy2                          3.4.5\n",
      "rsa                           4.9\n",
      "scikit-image                  0.18.3\n",
      "scikit-learn                  1.0.2\n",
      "scipy                         1.7.3\n",
      "screen-resolution-extra       0.0.0\n",
      "scs                           3.2.0\n",
      "seaborn                       0.11.2\n",
      "Send2Trash                    1.8.0\n",
      "setuptools                    57.4.0\n",
      "setuptools-git                1.2\n",
      "Shapely                       1.8.4\n",
      "six                           1.15.0\n",
      "sklearn-pandas                1.8.0\n",
      "smart-open                    5.2.1\n",
      "snowballstemmer               2.2.0\n",
      "sortedcontainers              2.4.0\n",
      "SoundFile                     0.10.3.post1\n",
      "spacy                         3.4.1\n",
      "spacy-legacy                  3.0.10\n",
      "spacy-loggers                 1.0.3\n",
      "Sphinx                        1.8.6\n",
      "sphinxcontrib-serializinghtml 1.1.5\n",
      "sphinxcontrib-websupport      1.2.4\n",
      "SQLAlchemy                    1.4.41\n",
      "sqlparse                      0.4.2\n",
      "srsly                         2.4.4\n",
      "statsmodels                   0.12.2\n",
      "sympy                         1.7.1\n",
      "tables                        3.7.0\n",
      "tabulate                      0.8.10\n",
      "tblib                         1.7.0\n",
      "tenacity                      8.0.1\n",
      "tensorboard                   2.8.0\n",
      "tensorboard-data-server       0.6.1\n",
      "tensorboard-plugin-wit        1.8.1\n",
      "tensorflow                    2.8.2+zzzcolab20220719082949\n",
      "tensorflow-datasets           4.6.0\n",
      "tensorflow-estimator          2.8.0\n",
      "tensorflow-gcs-config         2.8.0\n",
      "tensorflow-hub                0.12.0\n",
      "tensorflow-io-gcs-filesystem  0.26.0\n",
      "tensorflow-metadata           1.10.0\n",
      "tensorflow-probability        0.16.0\n",
      "termcolor                     1.1.0\n",
      "terminado                     0.13.3\n",
      "testpath                      0.6.0\n",
      "text-unidecode                1.3\n",
      "textblob                      0.15.3\n",
      "thinc                         8.1.0\n",
      "threadpoolctl                 3.1.0\n",
      "tifffile                      2021.11.2\n",
      "toml                          0.10.2\n",
      "tomli                         2.0.1\n",
      "toolz                         0.12.0\n",
      "torch                         1.12.1+cu113\n",
      "torchaudio                    0.12.1+cu113\n",
      "torchsummary                  1.5.1\n",
      "torchtext                     0.13.1\n",
      "torchvision                   0.13.1+cu113\n",
      "tornado                       5.1.1\n",
      "tqdm                          4.64.1\n",
      "traitlets                     5.1.1\n",
      "tweepy                        3.10.0\n",
      "typeguard                     2.7.1\n",
      "typer                         0.4.2\n",
      "typing-extensions             4.1.1\n",
      "tzlocal                       1.5.1\n",
      "ujson                         5.4.0\n",
      "uritemplate                   3.0.1\n",
      "urllib3                       1.24.3\n",
      "vega-datasets                 0.9.0\n",
      "wasabi                        0.10.1\n",
      "wcwidth                       0.2.5\n",
      "webargs                       8.2.0\n",
      "webencodings                  0.5.1\n",
      "Werkzeug                      1.0.1\n",
      "wheel                         0.37.1\n",
      "widgetsnbextension            3.6.1\n",
      "wordcloud                     1.8.2.2\n",
      "wrapt                         1.14.1\n",
      "xarray                        0.20.2\n",
      "xarray-einstats               0.2.2\n",
      "xgboost                       0.90\n",
      "xkit                          0.0.0\n",
      "xlrd                          1.1.0\n",
      "xlwt                          1.3.0\n",
      "yarl                          1.8.1\n",
      "yellowbrick                   1.5\n",
      "zict                          2.2.0\n",
      "zipp                          3.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VucI2O4Uytjy"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "id": "ahrb2Bbaytnt",
    "outputId": "a5dcdc5b-3cf7-42da-896b-61b30d7aa5c2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-9978b453-a9a9-425d-a06e-191d25ac92be\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9978b453-a9a9-425d-a06e-191d25ac92be')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-9978b453-a9a9-425d-a06e-191d25ac92be button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-9978b453-a9a9-425d-a06e-191d25ac92be');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Churn_Modelling.csv',delimiter = ',')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "id": "AIaD3rznytuZ",
    "outputId": "ac0bb8b1-826c-4d92-d6cd-9cf307cdf572"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-911e1f3b-9db0-43db-814a-5c7920820b95\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-911e1f3b-9db0-43db-814a-5c7920820b95')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-911e1f3b-9db0-43db-814a-5c7920820b95 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-911e1f3b-9db0-43db-814a-5c7920820b95');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redundant_cols = ['RowNumber','CustomerId','Surname']\n",
    "data = data.drop(columns = redundant_cols)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X2xD8ANUytxG",
    "outputId": "2ea13c39-8f66-4ff8-a411-06ae1d5b8e6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, array(['France', 'Spain', 'Germany'], dtype=object))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Geography.nunique(), data.Geography.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9aIMz3uzydP",
    "outputId": "7dff6e4f-7589-43d8-b0ef-f7687cd519ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, array(['Female', 'Male'], dtype=object))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Gender.nunique(), data.Gender.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "26lFuzIazyhH"
   },
   "outputs": [],
   "source": [
    "# Encoding Geography\n",
    "geo_ohe = pd.get_dummies(data.Geography, prefix = 'Geography')\n",
    "data = pd.concat((data,geo_ohe), axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "s1KSBLJizykq"
   },
   "outputs": [],
   "source": [
    "# Encoding the Gender column\n",
    "gen_ohe = pd.get_dummies(data.Gender, prefix = 'Gender')\n",
    "data = pd.concat((data,gen_ohe), axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "id": "DtgRh4MSzyn4",
    "outputId": "8cfe6d27-4e33-43a4-9b6c-c49b26f45eed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-8091dd03-c639-406c-a3bd-34e247976fe9\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8091dd03-c639-406c-a3bd-34e247976fe9')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-8091dd03-c639-406c-a3bd-34e247976fe9 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-8091dd03-c639-406c-a3bd-34e247976fe9');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0          1               1        101348.88       1                 1   \n",
       "1          0               1        112542.58       0                 0   \n",
       "2          1               0        113931.57       1                 1   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  Gender_Female  Gender_Male  \n",
       "0                  0                0              1            0  \n",
       "1                  0                1              1            0  \n",
       "2                  0                0              1            0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "id": "7dNNdVNxzyrb",
    "outputId": "7a326daf-4726-4dc9-920a-0c7cee4825f0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-9690391b-8d75-4010-88e9-179738da36ad\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9690391b-8d75-4010-88e9-179738da36ad')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-9690391b-8d75-4010-88e9-179738da36ad button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-9690391b-8d75-4010-88e9-179738da36ad');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0               1        101348.88       1                 1   \n",
       "1               1        112542.58       0                 0   \n",
       "2               0        113931.57       1                 1   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  Gender_Female  Gender_Male  \n",
       "0                  0                0              1            0  \n",
       "1                  0                1              1            0  \n",
       "2                  0                0              1            0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns = ['Geography','Gender'])\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "NHwEl6Eg2-Wi"
   },
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "train, test = train_test_split(data, test_size = 0.2, random_state = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "id": "tN4sN1MQzyvL",
    "outputId": "bd70406b-3f73-45db-81c2-a43967199c01"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-2197b082-13fe-4b9c-b9a5-87ef261b8cc5\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.442</td>\n",
       "      <td>0.391892</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.561831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.358</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.466028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.612</td>\n",
       "      <td>0.364865</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.581644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2197b082-13fe-4b9c-b9a5-87ef261b8cc5')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-2197b082-13fe-4b9c-b9a5-87ef261b8cc5 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-2197b082-13fe-4b9c-b9a5-87ef261b8cc5');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   CreditScore       Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "0        0.442  0.391892     0.7  0.000000       0.333333        0.0   \n",
       "1        0.358  0.216216     0.9  0.000000       0.000000        1.0   \n",
       "2        0.612  0.364865     0.7  0.581644       0.000000        1.0   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0             0.0         0.561831     0.0               1.0   \n",
       "1             1.0         0.466028     0.0               0.0   \n",
       "2             1.0         0.996998     0.0               1.0   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  Gender_Female  Gender_Male  \n",
       "0                0.0              0.0            1.0          0.0  \n",
       "1                0.0              1.0            0.0          1.0  \n",
       "2                0.0              0.0            1.0          0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling the data\n",
    "\n",
    "# Training data\n",
    "tr_scaler = MinMaxScaler()\n",
    "tr_sc = pd.DataFrame(tr_scaler.fit_transform(train), columns = train.columns)\n",
    "tr_sc.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "id": "6IcMODByzyyV",
    "outputId": "5d8e5ec6-49da-425b-c74e-cb6d24b09083"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-da8856f7-dd1f-4cb4-b701-059aa46c556d\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.474</td>\n",
       "      <td>0.587302</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.322775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.670</td>\n",
       "      <td>0.396825</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.539040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.673897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da8856f7-dd1f-4cb4-b701-059aa46c556d')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-da8856f7-dd1f-4cb4-b701-059aa46c556d button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-da8856f7-dd1f-4cb4-b701-059aa46c556d');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   CreditScore       Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "0        0.474  0.587302     0.9  0.000000       0.000000        1.0   \n",
       "1        0.670  0.396825     0.9  0.000000       0.333333        1.0   \n",
       "2        0.884  0.015873     0.7  0.673897       0.000000        1.0   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0             0.0         0.322775     0.0               1.0   \n",
       "1             0.0         0.539040     0.0               0.0   \n",
       "2             0.0         0.166097     0.0               1.0   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  Gender_Female  Gender_Male  \n",
       "0                0.0              0.0            0.0          1.0  \n",
       "1                0.0              1.0            0.0          1.0  \n",
       "2                0.0              0.0            0.0          1.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing data\n",
    "ts_scaler = MinMaxScaler()\n",
    "ts_sc = pd.DataFrame(ts_scaler.fit_transform(test), columns = test.columns)\n",
    "ts_sc.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "-E0zmJsa5xNf"
   },
   "outputs": [],
   "source": [
    "tr_x, tr_y = tr_sc.drop(columns = ['Exited']), tr_sc[['Exited']]\n",
    "ts_x, ts_y = ts_sc.drop(columns = ['Exited']), ts_sc[['Exited']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lrqVguRK6Fe5",
    "outputId": "8a14c64f-d0f8-4ce2-838f-001b949de295"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 13)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCUVAfLLzy1f"
   },
   "source": [
    "# Building the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmqojsDpzy48"
   },
   "source": [
    "# Model Building\n",
    "1. Initializing the Sequential Contianer\n",
    "2. Adding the layers {Building the structure of the Neural Network}\n",
    "3. Compiling the neural network {Describing the optimization and loss functions and the metrics to monitor}\n",
    "\n",
    "# Model Training\n",
    "# Model Evaluation\n",
    "# Model Saving\n",
    "# Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "h9dnOmMx4rc8"
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------Model Building\n",
    "# Initializingthe Sequantial container\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Adding layers\n",
    "# ---------Adding the input layer\n",
    "model.add(tf.keras.layers.Input(shape = (13,)))\n",
    "\n",
    "# ---------Adding the 1st hidden layer\n",
    "model.add(tf.keras.layers.Dense(units = 6, \n",
    "                                activation = 'relu', \n",
    "                                kernel_initializer = 'he_normal'))\n",
    "# ---------Adding the 2nd hidden layer\n",
    "model.add(tf.keras.layers.Dense(units = 8, \n",
    "                                activation = 'sigmoid', \n",
    "                                kernel_initializer = 'glorot_normal'))\n",
    "\n",
    "# ---------Adding the output layer\n",
    "model.add(tf.keras.layers.Dense(units = 1, \n",
    "                                activation = 'sigmoid', \n",
    "                                kernel_initializer = 'glorot_normal'))\n",
    "# -----------------------------------------------Model Building\n",
    "\n",
    "# -----------------------------------------------Model Compilation\n",
    "model.compile(optimizer = 'Adam',\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['accuracy','Precision','Recall'])\n",
    "# -----------------------------------------------Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vNPWoLiB4raq",
    "outputId": "fc8b9775-6e37-4a40-c9ae-9edfda53dbc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 6)                 84        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 56        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149\n",
      "Trainable params: 149\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarizing the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pi8kG8su4rYJ",
    "outputId": "79f2c2c4-1773-4f57-f69e-3ccf03e24619"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sequential',\n",
       " 'layers': [{'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, 13),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'ragged': False,\n",
       "    'name': 'input_1'}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 6,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'HeNormal', 'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 8,\n",
       "    'activation': 'sigmoid',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotNormal',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 1,\n",
       "    'activation': 'sigmoid',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotNormal',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}}]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the detailed configuration of the model\n",
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aM1Hz_9_4rVw",
    "outputId": "b5111433-2783-4a2f-a898-38d3ba3d902e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "16/16 [==============================] - 5s 28ms/step - loss: 0.7618 - accuracy: 0.2101 - precision: 0.2058 - recall: 0.9939 - val_loss: 0.7263 - val_accuracy: 0.2580 - val_precision: 0.1953 - val_recall: 0.8929\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6998 - accuracy: 0.4850 - precision: 0.2166 - recall: 0.5751 - val_loss: 0.6698 - val_accuracy: 0.6925 - val_precision: 0.1841 - val_recall: 0.1658\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6502 - accuracy: 0.7511 - precision: 0.2297 - recall: 0.0894 - val_loss: 0.6248 - val_accuracy: 0.8005 - val_precision: 0.2308 - val_recall: 0.0077\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6110 - accuracy: 0.7944 - precision: 0.5000 - recall: 0.0043 - val_loss: 0.5900 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5814 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5632 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5588 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5435 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5426 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5290 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5310 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5184 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5227 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5107 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5167 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5052 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5126 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5012 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5096 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4983 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5074 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4961 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5058 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4944 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5045 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4931 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5035 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4918 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5025 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4908 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5016 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4898 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5008 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4889 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4999 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4879 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4991 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4870 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4983 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4860 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4974 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4851 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4966 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4841 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4957 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4831 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4948 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4821 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4939 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4811 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4930 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4800 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4921 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4790 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4912 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4780 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4902 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4770 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4893 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4759 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4884 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4749 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4874 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4738 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4865 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4726 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4855 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4715 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4845 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4705 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4836 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4696 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4826 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4684 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4816 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4675 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4806 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4666 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4797 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4656 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4788 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4644 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4778 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4635 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4769 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4626 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4760 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4616 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4751 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4609 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4742 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4600 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4733 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4588 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4724 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4579 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4715 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4572 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4706 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4563 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4554 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4547 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4539 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4671 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4530 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4520 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4655 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4515 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4648 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4510 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4639 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4499 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4632 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4489 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4623 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4485 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4616 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4481 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4608 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4469 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4600 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4466 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4593 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4456 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4585 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4451 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4577 - accuracy: 0.7945 - precision: 0.6667 - recall: 0.0012 - val_loss: 0.4443 - val_accuracy: 0.8055 - val_precision: 0.8000 - val_recall: 0.0102\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4570 - accuracy: 0.7960 - precision: 0.8824 - recall: 0.0091 - val_loss: 0.4437 - val_accuracy: 0.8050 - val_precision: 0.5833 - val_recall: 0.0179\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4562 - accuracy: 0.7965 - precision: 0.8148 - recall: 0.0134 - val_loss: 0.4430 - val_accuracy: 0.8065 - val_precision: 0.6316 - val_recall: 0.0306\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4556 - accuracy: 0.7979 - precision: 0.8684 - recall: 0.0201 - val_loss: 0.4427 - val_accuracy: 0.8065 - val_precision: 0.5926 - val_recall: 0.0408\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4548 - accuracy: 0.7979 - precision: 0.8684 - recall: 0.0201 - val_loss: 0.4413 - val_accuracy: 0.8065 - val_precision: 0.6000 - val_recall: 0.0383\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4540 - accuracy: 0.7994 - precision: 0.9000 - recall: 0.0274 - val_loss: 0.4410 - val_accuracy: 0.8070 - val_precision: 0.5789 - val_recall: 0.0561\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4533 - accuracy: 0.8002 - precision: 0.8507 - recall: 0.0347 - val_loss: 0.4405 - val_accuracy: 0.8095 - val_precision: 0.6170 - val_recall: 0.0740\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4525 - accuracy: 0.8019 - precision: 0.8488 - recall: 0.0444 - val_loss: 0.4400 - val_accuracy: 0.8095 - val_precision: 0.6078 - val_recall: 0.0791\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4517 - accuracy: 0.8021 - precision: 0.8444 - recall: 0.0462 - val_loss: 0.4389 - val_accuracy: 0.8105 - val_precision: 0.6275 - val_recall: 0.0816\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4510 - accuracy: 0.8027 - precision: 0.8454 - recall: 0.0498 - val_loss: 0.4387 - val_accuracy: 0.8120 - val_precision: 0.6333 - val_recall: 0.0969\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4503 - accuracy: 0.8041 - precision: 0.8421 - recall: 0.0584 - val_loss: 0.4381 - val_accuracy: 0.8145 - val_precision: 0.6522 - val_recall: 0.1148\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4495 - accuracy: 0.8040 - precision: 0.8348 - recall: 0.0584 - val_loss: 0.4371 - val_accuracy: 0.8135 - val_precision: 0.6418 - val_recall: 0.1097\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4487 - accuracy: 0.8040 - precision: 0.8235 - recall: 0.0596 - val_loss: 0.4367 - val_accuracy: 0.8175 - val_precision: 0.6800 - val_recall: 0.1301\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4480 - accuracy: 0.8066 - precision: 0.8311 - recall: 0.0748 - val_loss: 0.4365 - val_accuracy: 0.8175 - val_precision: 0.6627 - val_recall: 0.1403\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4472 - accuracy: 0.8059 - precision: 0.8333 - recall: 0.0699 - val_loss: 0.4349 - val_accuracy: 0.8180 - val_precision: 0.6750 - val_recall: 0.1378\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4463 - accuracy: 0.8069 - precision: 0.8289 - recall: 0.0766 - val_loss: 0.4351 - val_accuracy: 0.8185 - val_precision: 0.6526 - val_recall: 0.1582\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4455 - accuracy: 0.8076 - precision: 0.8046 - recall: 0.0851 - val_loss: 0.4347 - val_accuracy: 0.8200 - val_precision: 0.6600 - val_recall: 0.1684\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4447 - accuracy: 0.8075 - precision: 0.8070 - recall: 0.0839 - val_loss: 0.4335 - val_accuracy: 0.8210 - val_precision: 0.6667 - val_recall: 0.1735\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4438 - accuracy: 0.8081 - precision: 0.7926 - recall: 0.0906 - val_loss: 0.4332 - val_accuracy: 0.8200 - val_precision: 0.6455 - val_recall: 0.1811\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4432 - accuracy: 0.8092 - precision: 0.7692 - recall: 0.1033 - val_loss: 0.4329 - val_accuracy: 0.8210 - val_precision: 0.6466 - val_recall: 0.1913\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4423 - accuracy: 0.8087 - precision: 0.7650 - recall: 0.1009 - val_loss: 0.4319 - val_accuracy: 0.8205 - val_precision: 0.6387 - val_recall: 0.1939\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.8091 - precision: 0.7611 - recall: 0.1046 - val_loss: 0.4313 - val_accuracy: 0.8205 - val_precision: 0.6364 - val_recall: 0.1964\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4410 - accuracy: 0.8091 - precision: 0.7543 - recall: 0.1064 - val_loss: 0.4306 - val_accuracy: 0.8195 - val_precision: 0.6260 - val_recall: 0.1964\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4401 - accuracy: 0.8094 - precision: 0.7400 - recall: 0.1125 - val_loss: 0.4315 - val_accuracy: 0.8210 - val_precision: 0.6232 - val_recall: 0.2194\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4396 - accuracy: 0.8109 - precision: 0.7245 - recall: 0.1295 - val_loss: 0.4309 - val_accuracy: 0.8195 - val_precision: 0.6069 - val_recall: 0.2245\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4391 - accuracy: 0.8100 - precision: 0.7323 - recall: 0.1198 - val_loss: 0.4298 - val_accuracy: 0.8195 - val_precision: 0.6069 - val_recall: 0.2245\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4383 - accuracy: 0.8109 - precision: 0.7171 - recall: 0.1325 - val_loss: 0.4308 - val_accuracy: 0.8225 - val_precision: 0.6209 - val_recall: 0.2423\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4378 - accuracy: 0.8110 - precision: 0.7254 - recall: 0.1301 - val_loss: 0.4292 - val_accuracy: 0.8205 - val_precision: 0.6138 - val_recall: 0.2270\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4372 - accuracy: 0.8111 - precision: 0.7006 - recall: 0.1422 - val_loss: 0.4307 - val_accuracy: 0.8190 - val_precision: 0.5904 - val_recall: 0.2500\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4366 - accuracy: 0.8109 - precision: 0.6886 - recall: 0.1465 - val_loss: 0.4284 - val_accuracy: 0.8215 - val_precision: 0.6115 - val_recall: 0.2449\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4361 - accuracy: 0.8109 - precision: 0.6919 - recall: 0.1447 - val_loss: 0.4288 - val_accuracy: 0.8215 - val_precision: 0.6036 - val_recall: 0.2602\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4357 - accuracy: 0.8114 - precision: 0.6789 - recall: 0.1568 - val_loss: 0.4293 - val_accuracy: 0.8215 - val_precision: 0.6012 - val_recall: 0.2653\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4355 - accuracy: 0.8110 - precision: 0.7009 - recall: 0.1410 - val_loss: 0.4276 - val_accuracy: 0.8220 - val_precision: 0.6084 - val_recall: 0.2577\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4348 - accuracy: 0.8110 - precision: 0.6667 - recall: 0.1617 - val_loss: 0.4293 - val_accuracy: 0.8220 - val_precision: 0.5957 - val_recall: 0.2857\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4343 - accuracy: 0.8119 - precision: 0.6823 - recall: 0.1593 - val_loss: 0.4277 - val_accuracy: 0.8215 - val_precision: 0.5978 - val_recall: 0.2730\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4338 - accuracy: 0.8109 - precision: 0.6710 - recall: 0.1574 - val_loss: 0.4286 - val_accuracy: 0.8235 - val_precision: 0.6043 - val_recall: 0.2883\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4334 - accuracy: 0.8105 - precision: 0.6497 - recall: 0.1702 - val_loss: 0.4280 - val_accuracy: 0.8210 - val_precision: 0.5895 - val_recall: 0.2857\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4331 - accuracy: 0.8106 - precision: 0.6578 - recall: 0.1647 - val_loss: 0.4269 - val_accuracy: 0.8220 - val_precision: 0.5957 - val_recall: 0.2857\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4326 - accuracy: 0.8105 - precision: 0.6525 - recall: 0.1678 - val_loss: 0.4278 - val_accuracy: 0.8215 - val_precision: 0.5897 - val_recall: 0.2934\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4324 - accuracy: 0.8100 - precision: 0.6398 - recall: 0.1739 - val_loss: 0.4272 - val_accuracy: 0.8225 - val_precision: 0.5969 - val_recall: 0.2908\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4320 - accuracy: 0.8108 - precision: 0.6472 - recall: 0.1751 - val_loss: 0.4268 - val_accuracy: 0.8215 - val_precision: 0.5888 - val_recall: 0.2959\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4318 - accuracy: 0.8109 - precision: 0.6422 - recall: 0.1812 - val_loss: 0.4271 - val_accuracy: 0.8210 - val_precision: 0.5850 - val_recall: 0.2985\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4314 - accuracy: 0.8112 - precision: 0.6552 - recall: 0.1733 - val_loss: 0.4261 - val_accuracy: 0.8220 - val_precision: 0.5918 - val_recall: 0.2959\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4311 - accuracy: 0.8104 - precision: 0.6391 - recall: 0.1787 - val_loss: 0.4277 - val_accuracy: 0.8205 - val_precision: 0.5813 - val_recall: 0.3010\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4308 - accuracy: 0.8116 - precision: 0.6444 - recall: 0.1872 - val_loss: 0.4270 - val_accuracy: 0.8210 - val_precision: 0.5833 - val_recall: 0.3036\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4306 - accuracy: 0.8106 - precision: 0.6360 - recall: 0.1848 - val_loss: 0.4269 - val_accuracy: 0.8220 - val_precision: 0.5874 - val_recall: 0.3087\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4303 - accuracy: 0.8110 - precision: 0.6424 - recall: 0.1824 - val_loss: 0.4262 - val_accuracy: 0.8205 - val_precision: 0.5805 - val_recall: 0.3036\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4300 - accuracy: 0.8119 - precision: 0.6373 - recall: 0.1976 - val_loss: 0.4276 - val_accuracy: 0.8195 - val_precision: 0.5714 - val_recall: 0.3163\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4299 - accuracy: 0.8112 - precision: 0.6392 - recall: 0.1884 - val_loss: 0.4257 - val_accuracy: 0.8220 - val_precision: 0.5865 - val_recall: 0.3112\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.8119 - precision: 0.6373 - recall: 0.1976 - val_loss: 0.4278 - val_accuracy: 0.8190 - val_precision: 0.5676 - val_recall: 0.3214\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.8120 - precision: 0.6328 - recall: 0.2043 - val_loss: 0.4265 - val_accuracy: 0.8210 - val_precision: 0.5780 - val_recall: 0.3214\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4293 - accuracy: 0.8117 - precision: 0.6445 - recall: 0.1884 - val_loss: 0.4263 - val_accuracy: 0.8200 - val_precision: 0.5727 - val_recall: 0.3214\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4290 - accuracy: 0.8125 - precision: 0.6360 - recall: 0.2061 - val_loss: 0.4275 - val_accuracy: 0.8175 - val_precision: 0.5600 - val_recall: 0.3214\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4289 - accuracy: 0.8121 - precision: 0.6300 - recall: 0.2091 - val_loss: 0.4266 - val_accuracy: 0.8185 - val_precision: 0.5650 - val_recall: 0.3214\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.8116 - precision: 0.6322 - recall: 0.2006 - val_loss: 0.4259 - val_accuracy: 0.8190 - val_precision: 0.5676 - val_recall: 0.3214\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4285 - accuracy: 0.8115 - precision: 0.6285 - recall: 0.2036 - val_loss: 0.4266 - val_accuracy: 0.8185 - val_precision: 0.5644 - val_recall: 0.3240\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4284 - accuracy: 0.8116 - precision: 0.6317 - recall: 0.2012 - val_loss: 0.4260 - val_accuracy: 0.8185 - val_precision: 0.5644 - val_recall: 0.3240\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4281 - accuracy: 0.8124 - precision: 0.6290 - recall: 0.2134 - val_loss: 0.4271 - val_accuracy: 0.8190 - val_precision: 0.5652 - val_recall: 0.3316\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4280 - accuracy: 0.8123 - precision: 0.6279 - recall: 0.2134 - val_loss: 0.4258 - val_accuracy: 0.8185 - val_precision: 0.5650 - val_recall: 0.3214\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.8116 - precision: 0.6307 - recall: 0.2024 - val_loss: 0.4262 - val_accuracy: 0.8190 - val_precision: 0.5652 - val_recall: 0.3316\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4277 - accuracy: 0.8124 - precision: 0.6300 - recall: 0.2122 - val_loss: 0.4267 - val_accuracy: 0.8155 - val_precision: 0.5485 - val_recall: 0.3316\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4276 - accuracy: 0.8127 - precision: 0.6296 - recall: 0.2170 - val_loss: 0.4259 - val_accuracy: 0.8185 - val_precision: 0.5644 - val_recall: 0.3240\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4275 - accuracy: 0.8117 - precision: 0.6319 - recall: 0.2024 - val_loss: 0.4250 - val_accuracy: 0.8180 - val_precision: 0.5625 - val_recall: 0.3214\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4274 - accuracy: 0.8141 - precision: 0.6344 - recall: 0.2267 - val_loss: 0.4274 - val_accuracy: 0.8135 - val_precision: 0.5385 - val_recall: 0.3393\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4272 - accuracy: 0.8158 - precision: 0.6409 - recall: 0.2365 - val_loss: 0.4256 - val_accuracy: 0.8195 - val_precision: 0.5677 - val_recall: 0.3316\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4274 - accuracy: 0.8125 - precision: 0.6402 - recall: 0.2012 - val_loss: 0.4250 - val_accuracy: 0.8185 - val_precision: 0.5639 - val_recall: 0.3265\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4269 - accuracy: 0.8134 - precision: 0.6306 - recall: 0.2231 - val_loss: 0.4272 - val_accuracy: 0.8150 - val_precision: 0.5444 - val_recall: 0.3444\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4269 - accuracy: 0.8151 - precision: 0.6370 - recall: 0.2347 - val_loss: 0.4257 - val_accuracy: 0.8170 - val_precision: 0.5542 - val_recall: 0.3393\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4269 - accuracy: 0.8124 - precision: 0.6328 - recall: 0.2085 - val_loss: 0.4253 - val_accuracy: 0.8190 - val_precision: 0.5636 - val_recall: 0.3393\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4267 - accuracy: 0.8151 - precision: 0.6361 - recall: 0.2359 - val_loss: 0.4268 - val_accuracy: 0.8170 - val_precision: 0.5524 - val_recall: 0.3495\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4265 - accuracy: 0.8149 - precision: 0.6362 - recall: 0.2328 - val_loss: 0.4260 - val_accuracy: 0.8165 - val_precision: 0.5514 - val_recall: 0.3418\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4264 - accuracy: 0.8142 - precision: 0.6345 - recall: 0.2280 - val_loss: 0.4256 - val_accuracy: 0.8180 - val_precision: 0.5583 - val_recall: 0.3418\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4263 - accuracy: 0.8145 - precision: 0.6390 - recall: 0.2249 - val_loss: 0.4255 - val_accuracy: 0.8190 - val_precision: 0.5620 - val_recall: 0.3469\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4262 - accuracy: 0.8148 - precision: 0.6379 - recall: 0.2292 - val_loss: 0.4266 - val_accuracy: 0.8155 - val_precision: 0.5455 - val_recall: 0.3520\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4261 - accuracy: 0.8150 - precision: 0.6350 - recall: 0.2359 - val_loss: 0.4263 - val_accuracy: 0.8165 - val_precision: 0.5502 - val_recall: 0.3495\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4260 - accuracy: 0.8152 - precision: 0.6367 - recall: 0.2365 - val_loss: 0.4249 - val_accuracy: 0.8175 - val_precision: 0.5556 - val_recall: 0.3444\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4260 - accuracy: 0.8140 - precision: 0.6384 - recall: 0.2201 - val_loss: 0.4251 - val_accuracy: 0.8170 - val_precision: 0.5528 - val_recall: 0.3469\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4259 - accuracy: 0.8161 - precision: 0.6338 - recall: 0.2505 - val_loss: 0.4262 - val_accuracy: 0.8150 - val_precision: 0.5433 - val_recall: 0.3520\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4257 - accuracy: 0.8146 - precision: 0.6401 - recall: 0.2249 - val_loss: 0.4246 - val_accuracy: 0.8165 - val_precision: 0.5510 - val_recall: 0.3444\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4256 - accuracy: 0.8154 - precision: 0.6373 - recall: 0.2371 - val_loss: 0.4255 - val_accuracy: 0.8165 - val_precision: 0.5502 - val_recall: 0.3495\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4254 - accuracy: 0.8150 - precision: 0.6387 - recall: 0.2310 - val_loss: 0.4253 - val_accuracy: 0.8165 - val_precision: 0.5502 - val_recall: 0.3495\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4253 - accuracy: 0.8149 - precision: 0.6380 - recall: 0.2304 - val_loss: 0.4250 - val_accuracy: 0.8160 - val_precision: 0.5488 - val_recall: 0.3444\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4253 - accuracy: 0.8161 - precision: 0.6408 - recall: 0.2407 - val_loss: 0.4253 - val_accuracy: 0.8160 - val_precision: 0.5480 - val_recall: 0.3495\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4251 - accuracy: 0.8149 - precision: 0.6371 - recall: 0.2316 - val_loss: 0.4256 - val_accuracy: 0.8155 - val_precision: 0.5458 - val_recall: 0.3495\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4252 - accuracy: 0.8166 - precision: 0.6365 - recall: 0.2523 - val_loss: 0.4257 - val_accuracy: 0.8165 - val_precision: 0.5490 - val_recall: 0.3571\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4251 - accuracy: 0.8155 - precision: 0.6459 - recall: 0.2274 - val_loss: 0.4231 - val_accuracy: 0.8190 - val_precision: 0.5625 - val_recall: 0.3444\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4248 - accuracy: 0.8159 - precision: 0.6378 - recall: 0.2419 - val_loss: 0.4260 - val_accuracy: 0.8160 - val_precision: 0.5465 - val_recall: 0.3597\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4247 - accuracy: 0.8163 - precision: 0.6409 - recall: 0.2419 - val_loss: 0.4254 - val_accuracy: 0.8155 - val_precision: 0.5455 - val_recall: 0.3520\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4246 - accuracy: 0.8158 - precision: 0.6399 - recall: 0.2377 - val_loss: 0.4251 - val_accuracy: 0.8170 - val_precision: 0.5516 - val_recall: 0.3546\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4246 - accuracy: 0.8167 - precision: 0.6396 - recall: 0.2492 - val_loss: 0.4256 - val_accuracy: 0.8165 - val_precision: 0.5486 - val_recall: 0.3597\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4244 - accuracy: 0.8158 - precision: 0.6409 - recall: 0.2365 - val_loss: 0.4240 - val_accuracy: 0.8160 - val_precision: 0.5488 - val_recall: 0.3444\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4243 - accuracy: 0.8164 - precision: 0.6447 - recall: 0.2383 - val_loss: 0.4253 - val_accuracy: 0.8165 - val_precision: 0.5490 - val_recall: 0.3571\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4243 - accuracy: 0.8161 - precision: 0.6343 - recall: 0.2498 - val_loss: 0.4248 - val_accuracy: 0.8170 - val_precision: 0.5516 - val_recall: 0.3546\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4241 - accuracy: 0.8171 - precision: 0.6422 - recall: 0.2498 - val_loss: 0.4243 - val_accuracy: 0.8160 - val_precision: 0.5484 - val_recall: 0.3469\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4240 - accuracy: 0.8170 - precision: 0.6430 - recall: 0.2474 - val_loss: 0.4247 - val_accuracy: 0.8165 - val_precision: 0.5490 - val_recall: 0.3571\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4238 - accuracy: 0.8169 - precision: 0.6411 - recall: 0.2486 - val_loss: 0.4245 - val_accuracy: 0.8170 - val_precision: 0.5508 - val_recall: 0.3597\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4237 - accuracy: 0.8167 - precision: 0.6437 - recall: 0.2438 - val_loss: 0.4250 - val_accuracy: 0.8175 - val_precision: 0.5521 - val_recall: 0.3648\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4238 - accuracy: 0.8181 - precision: 0.6435 - recall: 0.2590 - val_loss: 0.4250 - val_accuracy: 0.8180 - val_precision: 0.5538 - val_recall: 0.3673\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4238 - accuracy: 0.8173 - precision: 0.6543 - recall: 0.2359 - val_loss: 0.4236 - val_accuracy: 0.8180 - val_precision: 0.5560 - val_recall: 0.3546\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4234 - accuracy: 0.8173 - precision: 0.6414 - recall: 0.2523 - val_loss: 0.4254 - val_accuracy: 0.8170 - val_precision: 0.5492 - val_recall: 0.3699\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4232 - accuracy: 0.8181 - precision: 0.6439 - recall: 0.2584 - val_loss: 0.4251 - val_accuracy: 0.8195 - val_precision: 0.5594 - val_recall: 0.3724\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4230 - accuracy: 0.8179 - precision: 0.6455 - recall: 0.2535 - val_loss: 0.4249 - val_accuracy: 0.8180 - val_precision: 0.5530 - val_recall: 0.3724\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4231 - accuracy: 0.8179 - precision: 0.6516 - recall: 0.2456 - val_loss: 0.4245 - val_accuracy: 0.8160 - val_precision: 0.5455 - val_recall: 0.3673\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4228 - accuracy: 0.8176 - precision: 0.6392 - recall: 0.2596 - val_loss: 0.4257 - val_accuracy: 0.8170 - val_precision: 0.5481 - val_recall: 0.3776\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.8191 - precision: 0.6509 - recall: 0.2596 - val_loss: 0.4240 - val_accuracy: 0.8195 - val_precision: 0.5594 - val_recall: 0.3724\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4226 - accuracy: 0.8186 - precision: 0.6492 - recall: 0.2565 - val_loss: 0.4238 - val_accuracy: 0.8195 - val_precision: 0.5598 - val_recall: 0.3699\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.8175 - precision: 0.6544 - recall: 0.2383 - val_loss: 0.4239 - val_accuracy: 0.8195 - val_precision: 0.5594 - val_recall: 0.3724\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4223 - accuracy: 0.8192 - precision: 0.6470 - recall: 0.2663 - val_loss: 0.4259 - val_accuracy: 0.8170 - val_precision: 0.5474 - val_recall: 0.3827\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4221 - accuracy: 0.8196 - precision: 0.6540 - recall: 0.2608 - val_loss: 0.4239 - val_accuracy: 0.8200 - val_precision: 0.5611 - val_recall: 0.3750\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4220 - accuracy: 0.8191 - precision: 0.6533 - recall: 0.2565 - val_loss: 0.4237 - val_accuracy: 0.8200 - val_precision: 0.5606 - val_recall: 0.3776\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4218 - accuracy: 0.8195 - precision: 0.6507 - recall: 0.2638 - val_loss: 0.4256 - val_accuracy: 0.8180 - val_precision: 0.5511 - val_recall: 0.3852\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4218 - accuracy: 0.8207 - precision: 0.6611 - recall: 0.2632 - val_loss: 0.4241 - val_accuracy: 0.8210 - val_precision: 0.5649 - val_recall: 0.3776\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4217 - accuracy: 0.8195 - precision: 0.6484 - recall: 0.2669 - val_loss: 0.4245 - val_accuracy: 0.8185 - val_precision: 0.5543 - val_recall: 0.3776\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.8205 - precision: 0.6571 - recall: 0.2657 - val_loss: 0.4240 - val_accuracy: 0.8200 - val_precision: 0.5606 - val_recall: 0.3776\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4214 - accuracy: 0.8195 - precision: 0.6598 - recall: 0.2523 - val_loss: 0.4237 - val_accuracy: 0.8205 - val_precision: 0.5632 - val_recall: 0.3750\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4212 - accuracy: 0.8209 - precision: 0.6532 - recall: 0.2748 - val_loss: 0.4262 - val_accuracy: 0.8180 - val_precision: 0.5500 - val_recall: 0.3929\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4212 - accuracy: 0.8209 - precision: 0.6596 - recall: 0.2663 - val_loss: 0.4243 - val_accuracy: 0.8200 - val_precision: 0.5597 - val_recall: 0.3827\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4210 - accuracy: 0.8209 - precision: 0.6626 - recall: 0.2626 - val_loss: 0.4252 - val_accuracy: 0.8190 - val_precision: 0.5551 - val_recall: 0.3852\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4208 - accuracy: 0.8215 - precision: 0.6570 - recall: 0.2760 - val_loss: 0.4245 - val_accuracy: 0.8190 - val_precision: 0.5551 - val_recall: 0.3852\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4207 - accuracy: 0.8213 - precision: 0.6565 - recall: 0.2742 - val_loss: 0.4243 - val_accuracy: 0.8195 - val_precision: 0.5581 - val_recall: 0.3801\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4205 - accuracy: 0.8224 - precision: 0.6667 - recall: 0.2723 - val_loss: 0.4234 - val_accuracy: 0.8195 - val_precision: 0.5581 - val_recall: 0.3801\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4204 - accuracy: 0.8223 - precision: 0.6672 - recall: 0.2705 - val_loss: 0.4246 - val_accuracy: 0.8190 - val_precision: 0.5551 - val_recall: 0.3852\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.8224 - precision: 0.6623 - recall: 0.2778 - val_loss: 0.4243 - val_accuracy: 0.8190 - val_precision: 0.5551 - val_recall: 0.3852\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4201 - accuracy: 0.8230 - precision: 0.6706 - recall: 0.2736 - val_loss: 0.4238 - val_accuracy: 0.8195 - val_precision: 0.5576 - val_recall: 0.3827\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4199 - accuracy: 0.8231 - precision: 0.6691 - recall: 0.2766 - val_loss: 0.4236 - val_accuracy: 0.8200 - val_precision: 0.5597 - val_recall: 0.3827\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4198 - accuracy: 0.8234 - precision: 0.6726 - recall: 0.2748 - val_loss: 0.4242 - val_accuracy: 0.8195 - val_precision: 0.5572 - val_recall: 0.3852\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4196 - accuracy: 0.8234 - precision: 0.6721 - recall: 0.2754 - val_loss: 0.4238 - val_accuracy: 0.8195 - val_precision: 0.5572 - val_recall: 0.3852\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4196 - accuracy: 0.8238 - precision: 0.6700 - recall: 0.2815 - val_loss: 0.4243 - val_accuracy: 0.8195 - val_precision: 0.5572 - val_recall: 0.3852\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4193 - accuracy: 0.8232 - precision: 0.6667 - recall: 0.2809 - val_loss: 0.4234 - val_accuracy: 0.8200 - val_precision: 0.5597 - val_recall: 0.3827\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4192 - accuracy: 0.8234 - precision: 0.6691 - recall: 0.2790 - val_loss: 0.4237 - val_accuracy: 0.8210 - val_precision: 0.5625 - val_recall: 0.3903\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4189 - accuracy: 0.8238 - precision: 0.6705 - recall: 0.2809 - val_loss: 0.4249 - val_accuracy: 0.8195 - val_precision: 0.5556 - val_recall: 0.3954\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4188 - accuracy: 0.8240 - precision: 0.6695 - recall: 0.2845 - val_loss: 0.4241 - val_accuracy: 0.8190 - val_precision: 0.5547 - val_recall: 0.3878\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4186 - accuracy: 0.8244 - precision: 0.6760 - recall: 0.2802 - val_loss: 0.4240 - val_accuracy: 0.8195 - val_precision: 0.5564 - val_recall: 0.3903\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "logs = model.fit(x = tr_x,\n",
    "                 y = tr_y,\n",
    "                 batch_size = 512,\n",
    "                 epochs = 200,\n",
    "                 validation_data = (ts_x, ts_y),\n",
    "                 use_multiprocessing = True,\n",
    "                 workers = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0DYpFYqx4rTW",
    "outputId": "d805e038-e2b3-4f8c-ff99-91824d090925"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.callbacks.History"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rpM1Gwwl4rQ1"
   },
   "outputs": [],
   "source": [
    "logs.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fGscUZZb4rOM"
   },
   "outputs": [],
   "source": [
    "logs.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "W0OVyudV_QW5"
   },
   "outputs": [],
   "source": [
    "def vizualiser(history_object, metric):\n",
    "  epochs = history_object.epoch\n",
    "  training_metric_data = history_object.history.get(metric)\n",
    "  validation_metric_data = history_object.history.get(f'val_{metric}')\n",
    "\n",
    "  plt.figure(figsize = (10,7))\n",
    "  sns.lineplot(x = epochs, y = training_metric_data)\n",
    "  sns.lineplot(x = epochs, y = validation_metric_data)\n",
    "  plt.legend([metric.title(),f'val {metric}'.title()])\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "bkydNgWM_WXj",
    "outputId": "66fbafdd-cb90-4f1d-9555-5f4ecc559af0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vizualiser(logs,'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "7Mcyr7nS_WVB",
    "outputId": "25098a71-c995-4d45-f621-4556ba8c94eb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlkAAAGbCAYAAAD3MIVlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXzc1X3v/9eZXaN9t2zJKzZehY1lMDisZjEQMISlOAtQyHqb9t5wbxtys6fl17RNWxpC8wtNSWiSxiFAwMQmDvsOsWyMF8n7qsWSLFn7MpqZc//4jm1hZFvLSCN73s/HYx7SfOf7nfmM4AHvxznn+znGWouIiIiIxJcr0QWIiIiInI0UskRERERGgEKWiIiIyAhQyBIREREZAQpZIiIiIiPAk+gCTpSXl2cnT56c6DJERERETmv9+vWHrbX5/b025kLW5MmTKS8vT3QZIiIiIqdljNl/stc0XSgiIiIyAhSyREREREaAQpaIiIjICBhza7JERERkdPT29lJVVUV3d3eiSxnzAoEAxcXFeL3eAV+jkCUiIpKkqqqqSE9PZ/LkyRhjEl3OmGWtpbGxkaqqKqZMmTLg6zRdKCIikqS6u7vJzc1VwDoNYwy5ubmDHvFTyBIREUliClgDM5S/k0KWiIiIyAhQyBIREZGESUtLS3QJI0YhS0RERGQEKGSJiIjImLJx40YWL15MaWkpt9xyC0eOHAHghz/8IbNnz6a0tJQ777wTgNdee4358+czf/58FixYQFtbWyJL/xC1cBARERG++9xWKmpa4/qes8dn8O0b5wz6urvuuouHH36Yyy67jG9961t897vf5aGHHuL73/8+e/fuxe/309zcDMAPfvADHnnkEZYsWUJ7ezuBQCCu32E4NJIlIiIiY0ZLSwvNzc1cdtllANx99928/vrrAJSWlvKpT32KX/7yl3g8zjjRkiVLuP/++/nhD39Ic3PzseNjwdipRERERBJmKCNOo2316tW8/vrrPPfcczz44INs3ryZBx54gBtuuIE1a9awZMkS1q5dy8yZMxNdKpCkI1m76ts51KItBERERMaazMxMsrOzeeONNwD4xS9+wWWXXUY0GuXgwYNcccUV/MM//AMtLS20t7eze/du5s2bx1e/+lUWLVrEtm3bEvwNjkvKkaxbHnmL28tK+NaNsxNdioiISFLr7OykuLj42PP777+fxx9/nC9+8Yt0dnYydepUfvaznxGJRPj0pz9NS0sL1lr+6q/+iqysLL75zW/yyiuv4HK5mDNnDtddd10Cv82HJWXICvjcdPWGE12GiIhI0otGo/0ef/fddz9y7M033/zIsYcffjjuNcVLUk4XBn1uukKRRJchIiIiZ7GkDFkpXjddvQpZIiIiMnKSM2T53HRqJEtERERGUHKGLK+bbo1kiYiIyAhKypAV1EiWiIiIjLCkDFkBrckSERGREZaUISvFq7sLRUREEu2KK65g7dq1Hzr20EMP8aUvfemk11x++eWUl5cP+HgiDShkGWOWGWO2G2N2GWMe6Of1fzXGbIw9dhhjmvu8Funz2qp4Fj9UQZ9GskRERBJtxYoVrFy58kPHVq5cyYoVKxJUUXydNmQZY9zAI8B1wGxghTHmQ63SrbVfsdbOt9bOBx4Gnu7zctfR16y1N8Wx9iELqE+WiIhIwt12222sXr2aUCgEwL59+6ipqeGSSy7hS1/6EmVlZcyZM4dvf/vbQ3r/pqYmbr75ZkpLS1m8eDGbNm0C4LXXXmP+/PnMnz+fBQsW0NbWRm1tLZdeeinz589n7ty5x7b1GY6BdHy/ANhlrd0DYIxZCSwHKk5y/gpgaH+NURL0eugJR4lELW6XSXQ5IiIiiff8A3Boc3zfc9w8uO77J305JyeHCy64gOeff57ly5ezcuVK7rjjDowxPPjgg+Tk5BCJRFi6dCmbNm2itLR0UB//7W9/mwULFvDMM8/w8ssvc9ddd7Fx40Z+8IMf8Mgjj7BkyRLa29sJBAI8+uijXHvttXz9618nEonQ2dk53G8/oOnCCcDBPs+rYsc+whgzCZgCvNzncMAYU26MedcYc/NJrvt87JzyhoaGAZY+dCk+52urjYOIiEhi9Z0y7DtV+MQTT3D++eezYMECtm7dSkXFycZ2Tu7NN9/kM5/5DABXXnkljY2NtLa2smTJEu6//35++MMf0tzcjMfjYdGiRfzsZz/jO9/5Dps3byY9PX3Y3y3eexfeCTxpre2bXiZZa6uNMVOBl40xm621u/teZK19FHgUoKyszMa5po9I8boB6AxFSPUn5faNIiIiH3aKEaeRtHz5cr7yla+wYcMGOjs7WbhwIXv37uUHP/gB69atIzs7m3vuuYfu7u64feYDDzzADTfcwJo1a1iyZAlr167l0ksv5fXXX2f16tXcc8893H///dx1113D+pyBjGRVAyV9nhfHjvXnTuDXfQ9Ya6tjP/cArwILBl1lnKX4nGClkSwREZHESktL44orruDee+89NorV2tpKamoqmZmZ1NXV8fzzzw/pvS+55BJ+9atfAfDqq6+Sl5dHRkYGu3fvZt68eXz1q19l0aJFbNu2jf3791NYWMjnPvc5PvvZz7Jhw4Zhf7eBDOOsA6YbY6bghKs7gU+eeJIxZiaQDbzT51g20Gmt7THG5AFLgH8cdtXD1HckS0RERBJrxYoV3HLLLcemDc877zwWLFjAzJkzKSkpYcmSJQN6nxtuuAGv1wvARRddxE9+8hPuvfdeSktLCQaDPP7444DTJuKVV17B5XIxZ84crrvuOlauXMk//dM/4fV6SUtL47/+67+G/b2MtaefnTPGXA88BLiBx6y1DxpjvgeUW2tXxc75DhCw1j7Q57qLgZ8AUZxRs4estf95qs8qKyuzI93n4pVt9fz5z9fxzF8sYX5J1oh+loiIyFhVWVnJrFmzEl3GGaO/v5cxZr21tqy/8we0IMlauwZYc8Kxb53w/Dv9XPc2MG8gnzGaAsdGssIJrkRERETOVknZ8T3oc0KW1mSJiIjISEnKkJUSC1ldoWiCKxEREUmsgSwbkqH9nZIzZGm6UEREhEAgQGNjo4LWaVhraWxsJBAIDOq6pGwSlaLpQhEREYqLi6mqqmI0GoGf6QKBAMXFxYO6JjlDllo4iIiI4PV6mTJlSqLLOGsl9XRhl0ayREREZIQkZchyuQx+j4sujWSJiIjICEnKkAVOGweNZImIiMhISdqQleJ1a02WiIiIjJikDVkBjWSJiIjICErakBX0uenWSJaIiIiMkKQNWZouFBERkZGUvCHL59F0oYiIiIyY5A1ZXrVwEBERkZGTtCErqJEsERERGUFJG7ICWpMlIiIiIyhpQ1aK160NokVERGTEJOUG0Wx5iqkhF50hH9ZajDGJrkhERETOMsk5kvX7r1Da9DxRC6FINNHViIiIyFkoOUOWN5WA7QGgO6SQJSIiIvGXnCHLl4rfdgHQ2RtOcDEiIiJyNkrSkBXEH+0GUK8sERERGRFJGrLS8EVjI1kKWSIiIjICkjNkeYN4I07IUhsHERERGQnJGbJ8QTyRTkAjWSIiIjIykjRkpeEOOyNZ2lpHRERERkJyhixvEHfYGcnSwncREREZCckZsnypuI6GLI1kiYiIyAhI2pBlIiE8hDWSJSIiIiMiaUMWQJAejWSJiIjIiEjOkOUNApBmujWSJSIiIiMiOUOWLw2AHF9ELRxERERkRCRpyHJGsjI9vZouFBERkRGRpCHLWZOV4wnRFdIG0SIiIhJ/yRmyvE7IynCHNJIlIiIiIyI5Q1ZsujDDE9KaLBERERkRSRqyYiNZrpA2iBYREZERkZwhKzZdmO5SnywREREZGckZsmIjWWkuTReKiIjIyEjOkOVNAQypdNOtkCUiIiIjIDlDljHgSyXV9NCp6UIREREZAckZsgC8QVLQtjoiIiIyMgYUsowxy4wx240xu4wxD/Tz+r8aYzbGHjuMMc19XrvbGLMz9rg7nsUPiy+VgO2mJxwlErWJrkZERETOMp7TnWCMcQOPAFcDVcA6Y8wqa23F0XOstV/pc/5fAgtiv+cA3wbKAAusj117JK7fYih8qQQiPQB090ZI9Z/2TyEiIiIyYAMZyboA2GWt3WOtDQErgeWnOH8F8OvY79cCL1hrm2LB6gVg2XAKjhtfKoFoF4DaOIiIiEjcDSRkTQAO9nleFTv2EcaYScAU4OXBXGuM+bwxptwYU97Q0DCQuofPG8QX7Qags0chS0REROIr3gvf7wSetNYOKrVYax+11pZZa8vy8/PjXNJJ+FLxRTsBaO/RJtEiIiISXwMJWdVASZ/nxbFj/bmT41OFg712dPlS8USckayOkEKWiIiIxNdAQtY6YLoxZooxxocTpFadeJIxZiaQDbzT5/Ba4BpjTLYxJhu4JnYs8bxBPBGNZImIiMjIOO0tddbasDHmyzjhyA08Zq3daoz5HlBurT0auO4EVlprbZ9rm4wxf4sT1AC+Z61tiu9XGCJfKu6wE7I6FLJEREQkzgbUt8BauwZYc8Kxb53w/DsnufYx4LEh1jdyfKm4wl0YogpZIiIiEnfJ2/E9tkl0CiHauhWyREREJL6SN2R5gwCk0k2HWjiIiIhInCVvyPKlAZDpCenuQhEREYm7JA5ZzkhWni+suwtFREQk7pI4ZDlrsnK8YS18FxERkbhL3pDldUJWlrdXIUtERETiLnlDVmwkK9vTo+lCERERibukD1kZ7l7dXSgiIiJxl7whK9bCIcMd0nShiIiIxF3yhqzYSFa6K6TpQhEREYm7pA9ZaaZHI1kiIiISd8kbslxu8ARINd10hCJEo/b014iIiIgMUPKGLABvkKDpAaCzV4vfRUREJH6SO2T50kihG0BThiIiIhJXSR6yggSiTsjS4ncRERGJpyQPWan4rEayREREJP6SO2R5g/ginYBGskRERCS+kjtk+dLwRo+OZGnhu4iIiMRPkoesIO6wM5Kl6UIRERGJp+QOWd7jIUvThSIiIhJPyR2yfGm4NJIlIiIiIyDJQ1YQQh0YYxWyREREJK6SPGSlYmyUbJ+lTSFLRERE4ii5Q5bX2SQ6z9erkSwRERGJq+QOWT4nZOX6etXCQUREROIquUNWIAOAfG9IdxeKiIhIXCV3yPKnA5Dj7tF0oYiIiMRVkocsZyQr29OtkSwRERGJK4UsINvdTUdIIUtERETiJ8lDljNdmOnq0sJ3ERERiavkDlmxhe/ppkvThSIiIhJXyR2yvEEwLtLpIhSO0huJJroiEREROUskd8gyBvzppFrtXygiIiLxldwhC8CfSTAWsjRlKCIiIvGikOVPJxA9OpKlxe8iIiISHwpZgQz8kXZAI1kiIiISPwpZ/nR8kQ5Aa7JEREQkfhSy/Ol4e9sAhSwRERGJH4UsfwbuXk0XioiISHwpZPnTccVClkayREREJF4UsvwZmHA3XsJ0hHR3oYiIiMTHgEKWMWaZMWa7MWaXMeaBk5xzhzGmwhiz1Rjz332OR4wxG2OPVfEqPG4CRzeJ1tY6IiIiEj+e051gjHEDjwBXA1XAOmPMKmttRZ9zpgNfA5ZYa48YYwr6vEWXtXZ+nOuOn9gm0fm+Xk0XioiISNwMZCTrAmCXtXaPtTYErASWn3DO54BHrLVHAKy19fEtcwT5nZGsfG8P7d0KWSIiIhIfAwlZE4CDfZ5XxY71NQOYYYx5yxjzrjFmWZ/XAsaY8tjxm/v7AGPM52PnlDc0NAzqCwzbsZGsHto0kiUiIiJxctrpwkG8z3TgcqAYeN0YM89a2wxMstZWG2OmAi8bYzZba3f3vdha+yjwKEBZWZmNU00DEwtZed4eDnT1jupHi4iIyNlrICNZ1UBJn+fFsWN9VQGrrLW91tq9wA6c0IW1tjr2cw/wKrBgmDXHVyATgFxPDy0KWSIiIhInAwlZ64DpxpgpxhgfcCdw4l2Cz+CMYmGMycOZPtxjjMk2xvj7HF8CVDCWxEayst09tGlNloiIiMTJaacLrbVhY8yXgbWAG3jMWrvVGPM9oNxauyr22jXGmAogAvy1tbbRGHMx8BNjTBQn0H2/712JY0Js4XuWq0sjWSIiIhI3A1qTZa1dA6w54di3+vxugftjj77nvA3MG36ZI8jjB5eXDFc37T1hwpEoHrd6tIqIiMjwKE0YA/500ugE0JShiIiIxIVCFkAgg1TrhKzWbk0ZioiIyPApZAH400mJhSytyxIREZF4UMgC8Gfij7QD0Nql6UIREREZPoUsAH86vnAHoJEsERERiQ+FLAB/Op5wbCRLa7JEREQkDhSyAAIZuENtgEayREREJD4UssDp+t7ThtcNrQpZIiIiEgcKWQD+dEy0lzy/RrJEREQkPhSy4NjWOuMDvQpZIiIiEhcKWXAsZOX7Q7Sq47uIiIjEgUIWQMAJWYW+Ho1kiYiISFwoZIGz8B3I9fbQppAlIiIicaCQBcdCVo5HI1kiIiISHwpZcGxNVra7m9buXqy1CS5IREREznQKWXAsZGW6uumNWLp6IwkuSERERM50CllwbLownS5Am0SLiIjI8ClkAXh84AmQRieghqQiIiIyfApZR/nTCVonZGmTaBERERkuhayj/BmkRDsAaOlUyBIREZHhUcg6KiULf7gF0EiWiIiIDJ9C1lEpOXhDTsjSmiwREREZLoWso1KycXcfAXR3oYiIiAyfQtZRwRxMVzNpfo9GskRERGTYFLKOSsmBnhZyAi6tyRIREZFhU8g6KiUbgCJ/l0ayREREZNgUso4K5gAw3t9Nq0KWiIiIDJNC1lGxkaxCb6dGskRERGTYFLKOioWsAk8nbd26u1BERESGRyHrqNh0Ya7p0EiWiIiIDJtC1lGxkaxs0057T5hwJJrggkRERORMppB1lD8DXB4yTRuApgxFRERkWBSyjjIGUrJJjzohS72yREREZDgUsvpKySY1FrKaOxWyREREZOgUsvpKySEl7GwS3dQZSnAxIiIiciZTyOorJZtArxOyGtsVskRERGToFLL6CubgCTUD0Njek+BiRERE5EymkNVXSjam6wgBr4vGDo1kiYiIyNApZPWVko3p7aQoaDiskSwREREZBoWsvmJd3ycHe7QmS0RERIZFIauvFCdkFQe6adJ0oYiIiAyDQlZfsa11ivzdWvguIiIiwzKgkGWMWWaM2W6M2WWMeeAk59xhjKkwxmw1xvx3n+N3G2N2xh53x6vwERGbLiz0dnC4I4S1NsEFiYiIyJnKc7oTjDFu4BHgaqAKWGeMWWWtrehzznTga8ASa+0RY0xB7HgO8G2gDLDA+ti1R+L/VeIgNpKV7+4kFI7S3hMmPeBNcFEiIiJyJhrISNYFwC5r7R5rbQhYCSw/4ZzPAY8cDU/W2vrY8WuBF6y1TbHXXgCWxaf0ERBbk5Vj2gE1JBUREZGhG0jImgAc7PO8KnasrxnADGPMW8aYd40xywZxLcaYzxtjyo0x5Q0NDQOvPt58QfAEyCQWsjq0LktERESGJl4L3z3AdOByYAXwH8aYrIFebK191FpbZq0ty8/Pj1NJQ9Rnk+jDGskSERGRIRpIyKoGSvo8L44d66sKWGWt7bXW7gV24ISugVw7tqTkEAxr/0IREREZnoGErHXAdGPMFGOMD7gTWHXCOc/gjGJhjMnDmT7cA6wFrjHGZBtjsoFrYsfGrpRsfMc2idZ0oYiIiAzNae8utNaGjTFfxglHbuAxa+1WY8z3gHJr7SqOh6kKIAL8tbW2EcAY87c4QQ3ge9bappH4InETzMZ1eBfpAY/2LxQREZEhO23IArDWrgHWnHDsW31+t8D9sceJ1z4GPDa8MkdRSg50NZGX5lfIEhERkSFTx/cTpWRD1xFyg15NF4qIiMiQKWSdKJgDkRBFwagWvouIiMiQKWSdKNaQdEKgW32yREREZMgUsk4U21pngq+Tpo4Qkaj2LxQREZHBU8g6UVoBAOPcbUQtNHdqylBEREQGTyHrRLGQlWdivbJ0h6GIiIgMgULWiVKdkJXj7HXNYd1hKCIiIkOgkHUiXxD8GaSHnZ6pusNQREREhkIhqz9pBaSGGgFo0nShiIiIDIFCVn/SCvF1N2CM9i8UERGRoVHI6k9aAaa9jpygj8MayRIREZEhUMjqT9o4aK8nN82nkSwREREZEoWs/qQVQE8rRSmWhjaFLBERERk8haz+pBUCMD21i0Mt3QkuRkRERM5ECln9iYWsyYF26tp6tLWOiIiIDJpCVn9iXd+LfW1EopoyFBERkcFTyOpPbCRrnMvZWqe2pSuR1YiIiMgZSCGrP6l5YFzHttap1bosERERGSSFrP643BDMIzO2tU5Ns0ayREREZHAUsk4m3en6HvC6dIehiIiIDJpC1smkFWLa6xmfmaLpQhERERk0hayTSSuE9nrGZQa08F1EREQGTSHrZNIKoL2OooyARrJERERk0BSyTiatEKK9TE0LUdfaTTgSTXRFIiIicgZRyDqZWEPSif52ohYatFG0iIiIDIJC1snEGpIWe9sAqGnWlKGIiIgMnELWycRCVqGrGVDXdxERERkchayTiU0XZkecru/qlSUiIiKDoZB1Mv4M8KQQ6DlM0OfWdKGIiIgMikLWyRgDaQWYjnqKMgMcatV0oYiIiAycQtappBVC2yGKMlM0kiUiIiKDopB1KpkToKWKInV9FxERkUFSyDqVrEnQcpCiTD/1bT30qiGpiIiIDJBC1qlkT4JIiKn+VqyF+jY1JBUREZGBUcg6laxJAExyNQBwSFOGIiIiMkAKWaeSPRmA8bYegANNnQksRkRERM4kClmnklkMGHLDh3C7DHsaOhJdkYiIiJwhFLJOxeOH9CI8LQeYlBNkd0N7oisSERGRM4RC1ulkT4Lm/UzNT2N3vUayREREZGAUsk4naxIc2c+0glT2Hu4gErWJrkhERETOAApZp5M9CVqrmZ7rJxSJUnVEi99FRETk9AYUsowxy4wx240xu4wxD/Tz+j3GmAZjzMbY47N9Xov0Ob4qnsWPiqxJgGVmSguA1mWJiIjIgHhOd4Ixxg08AlwNVAHrjDGrrLUVJ5z6G2vtl/t5iy5r7fzhl5og2U6vrMlup1fW7voOrpyZyIJERETkTDCQkawLgF3W2j3W2hCwElg+smWNIbGGpGmd1eSm+jSSJSIiIgMykJA1ATjY53lV7NiJbjXGbDLGPGmMKelzPGCMKTfGvGuMubm/DzDGfD52TnlDQ8PAqx8NGePB5YXm/UzLT1PIEhERkQGJ18L354DJ1tpS4AXg8T6vTbLWlgGfBB4yxkw78WJr7aPW2jJrbVl+fn6cSooTl9tpShq7w3C3GpKKiIjIAAwkZFUDfUemimPHjrHWNlprj+6e/FNgYZ/XqmM/9wCvAguGUW9ixHplTctPo6kjRFNHKNEViYiIyBg3kJC1DphujJlijPEBdwIfukvQGFPU5+lNQGXseLYxxh/7PQ9YApy4YH7sO9orKz8NgD2aMhQREZHTOO3dhdbasDHmy8BawA08Zq3daoz5HlBurV0F/JUx5iYgDDQB98QunwX8xBgTxQl03+/nrsSxL3sSdB7mnEwDOG0cyibnJLgoERERGctOG7IArLVrgDUnHPtWn9+/Bnytn+veBuYNs8bEi91hON7U4/O4tC5LRERETksd3wciezIA7ub9TM1LZXe9pgtFRETk1BSyBiJvhvOzoZJpBWnsqG9LbD0iIiIy5ilkDUQgAzJLoK6CeRMyOdjURWN7z+mvExERkaSlkDVQBbOhvpIFJVkAbDzYnOCCREREZCxTyBqogllweAfzioK4XYb3DyhkiYiIyMkpZA1U4RyI9hJs28fMcekayRIREZFTUsgaqILZzs+6rSyYmMXGg81EojaxNYmIiMiYpZA1UHnTwbihvpL5Jdm094S1WbSIiIiclELWQHn8TtCqr2DBRGfx+/sHjiS4KBERERmrFLIGo2AW1G1lSm4qmSlercsSERGRk1LIGoyCOdC8H1dvB/NLsnSHoYiIiJyUQtZgFMYWvzdsY35JFtvr2mjvCSe2JhERERmTFLIGo2CW8zO2Lsta2KQpQxEREemHQtZgZE0GbxDqKlhQko3LwNu7GxNdlYiIiIxBClmD4XJB/kyoryAz6KVscg4vVtYluioREREZgxSyBmvcPKjdCNEoV88qZNuhNqqOdCa6KhERERljFLIGa+Ji6G6Bhkquml0IwEuV9QkuSkRERMYahazBmniR83P/20zJS2VqfqqmDEVEROQjFLIGK3sypBfBgXcAuHpWIe/uaaS1uzexdYmIiMiYopA1WMY4o1n73wFruWp2Ib0Ry+s7GhJdmYiIiIwhCllDMeliaKuB5v2cPzGb7KCXFys0ZSgiIiLHKWQNxbF1We/gdhmunFnIy9vq6e6NJLYuERERGTMUsoaiYDYEMuHA2wDctrCY1u4wqzbWJLgwERERGSsUsobC5YKSxc66LGDx1BzOLUzn52/vw1qb4OJERERkLFDIGqpJF0HjTmhvwBjDXRdPoqK2lfX7jyS6MhERERkDFLKGauLFzs/YlOEtCyaQHvDw87f3Ja4mERERGTMUsoZq/ALwZ8L2PwAQ9Hm4o6yEP2w5RF1rd4KLExERkURTyBoqjw9mXg/bV0M4BMBdF00iYi3/8fqeBBcnIiIiiaaQNRyzb3b2Mdz7OgCTclO5Y2EJP397H9sPtSW4OBEREUkkhazhmHYF+DOg4nfHDn31upmkBTx845nNutNQREQkiSlkDYfHD+deB9tWQ8TZuzAn1cfXrpvJun1HeHJ9VYILFBERkURRyBqu2cuh68ixKUOA2xeWsHBSNv/fmkpqmrsSWJyIiIgkikLWcE27EnxpUPHssUMul+Efbi0lHLHc93g5HT3hBBYoIiIiiaCQNVzeFJixDCqfg97jo1bnFKTx8CcXsP1QK//rNxuJRrU+S0REJJkoZMXDwruhqwk++PWHDl9+bgHf+vhsXqio4+vPbCEciSaoQBERERltClnxMPkSpznp2z+CaORDL9198WT+x+XT+PWfDnDf4+W0dfcmqEgREREZTQpZ8WAMLPmf0LTbudPwQy8Z/mbZTP7+E/N4awRAjqEAACAASURBVNdhbv3x21TUtCaoUBERERktClnxMusmyJ4Mbz0E/fTHWnHBRB6/9wKaOkLc9KM3+ec/bqcnHPno+4iIiMhZQSErXlxuuPgvoXo97H+r31OWnJPHC1+5jJvmj+fhl3dx1b+8xhPlB7VWS0RE5CykkBVP8z8FaYXwx298ZG3WUdmpPv7ljvn84r4LyErx8TdPbuKqf3mNR1/fTX2bNpYWERE5W5ixtvVLWVmZLS8vT3QZQ7f5SXjqPrjuH+HCL5zyVGstL1TU8ePXdvP+gWbcLsPlM/K5bWExS2cV4vMoA4uIiIxlxpj11tqyfl8bSMgyxiwD/g1wAz+11n7/hNfvAf4JqI4d+pG19qex1+4GvhE7/nfW2sdP9VlnfMiyFn55Kxz8E3z5T5AxfkCX7apv56kNVTy9oYq61h6yg16Wz5/AbQuLmTM+A2PMCBcuIiIigzWskGWMcQM7gKuBKmAdsMJaW9HnnHuAMmvtl0+4NgcoB8oAC6wHFlprj5zs8874kAXQtBf+fTFMvxru+IVz9+EARaKWN3Y28OT6Kv5YUUcoHGVGYRo3zBvPDaXjOKcgfQQLFxERkcE4VcjyDOD6C4Bd1to9sTdbCSwHKk55leNa4AVrbVPs2heAZcCvT3nVmS5nClz2VXjpu/D2w7DkrwZ8qdtluPzcAi4/t4CWzl5WbarhuY01PPTSDv71xR0KXCIiImeIgYSsCcDBPs+rgAv7Oe9WY8ylOKNeX7HWHjzJtRNOvNAY83ng8wATJ04cWOVj3ZL/BbUfwAvfhKwSmHPLoN8iM+jlM4sn8ZnFk6hr7eb5zbWs2XzoQ4Hr+nlF3DCviOmFClwiIiJjyUBC1kA8B/zaWttjjPkC8Dhw5UAvttY+CjwKznRhnGpKLJcLbvkJtB2Cp78Aqfkw+WNDfrvCjAD3LJnCPUumUNfazR+2HGL1plr+7aWdPPTiTgUuERGRMWYga7IuAr5jrb029vxrANbavz/J+W6gyVqbaYxZAVxurf1C7LWfAK9aa086XXhWrMnqq7MJHrsWjuyHW34Mc2+N69sfC1yba1m3rwlrYXpBGjeUKnCJiIiMtOEufPfgTAEuxbl7cB3wSWvt1j7nFFlra2O/3wJ81Vq7OLbwfT1wfuzUDTgL35tO9nlnXcgC6GiE33wKDrwDV34TPna/M9IVZ/Wt3TzfT+C6fl4RN5QWMUOBS0REJK7i0cLheuAhnBYOj1lrHzTGfA8ot9auMsb8PXATEAaagC9Za7fFrr0X+L+xt3rQWvuzU33WWRmyAMI98OxfwObfwpRL4aaHnW14Rkh9azd/2HqI3286HrjOLUznlvMnsHz+eIoyU0bss0VERJLFsEPWaDprQxY4PbQ2PA5rvwE2Cld8DRZ9FrwjG3iOjnA9u7GaDQeaMQYunpbLLQuKWTZ3HGn+eC3NExERSS4KWWNN80H4/Vdg1wuQXgSX/G84/y7w+Ef8o/cd7uB371fzu/erOdDUScDr4to547hlwQQ+dk4eHre6zIuIiAyUQtZYtfcNeOVBZ61WZglc9jdw3gpwe0f8o621rN9/hKffr2b1plpaunrJT/dz03njuWXBBHWZFxERGQCFrLHMWtj9shO2qtdDRrEzqrXg05D5kZZiI6InHOGVbfU8vaGaV7bX0xuxWr8lIiIyAApZZwJrYecf4b3/3wldxgXTr4WF98A5V4F7dNZNHekI8fvNtfxuQ5XWb4mIiJyGQtaZpmkvvP8LeP+X0F4H6ePhvDth/qcg75xRK0Prt0RERE5NIetMFemF7c87gWvXi84diSWLnanEOTeDf3T6Xp1s/dby88ZzW1kxM8dljEodIiIiY41C1tmgtRY2rYT3fwWNO8EbhNk3w4JPwaQlMEqL1Ptbv1VanMntZSXcVDqezODIL9oXEREZKxSyzibWQtU6Zypxy9MQanOams7/lHNnYlbJqJXS1BHimfereaL8INsOteHzONOJd5QVc/G0PNwu3Z0oIiJnN4Wss1WoEyqfc6YT970BGJh6Gcz/NMz6+Ig3OT3KWsvWmlZ+W36QZzbW0NLVy/jMALctLOa2hSVMzA2OSh0iIiKjTSErGRzZBxt/DRv/G1oOgD8T5t3qBK4J54/adGJ3b4QXK+t4oryKN3Y2YC0snprD7QtLuG7eOII+3Z0oIiJnD4WsZBKNOqNaG38FFasg3AX5M2PTiXdCWsGolVLT3MXTG6r47foq9jd2kub38PHSIm4vK+H8iVlqdioiImc8haxk1d0CW3/nLJav+hMYN0y/xrk7cca1o9JZHpzpxHX7jvBE+UFWb6qlqzfC1PxUbl9YwifOn0BhRmBU6hAREYk3hSyBhh2w8ZfwwUqn91baOFh4N5x/96h1lgdo7wmzZlMtv11/kHX7juAycMn0fG4vK+aqWYUEvO5Rq0VERGS4FLLkuEjY2Zh63X86vbeMC869DhbdB1MuB9foNRjde7iDp9ZX8dSGKmpbuskIeLhp/nhuX1hCaXGmphNFRGTMU8iS/jXthfU/d+5O7GyEnKlQdq+zfiuYM2plRKKWd3Y38tv1B/nDlkP0hKNML0jjE+cXc8uCCYzL1HSiiIiMTQpZcmrhHqh41hndOvguuP0w9xNQdh8Ul43anYkArd29rN5Uy5Prq1i/35lOXHJOHrctLOaa2eNI8Wk6UURExg6FLBm4uq1O2Nr0Gwi1w7h5Ttiadzv400a1lL2HO3h6QxVPb6imurmLNL+HG+YVcevCYhZNztZ0ooiIJJxClgxeTxtsegLKH4O6LeDPcFpAlN0HBTNHtZRo1PLe3iae2lDFms21dIYilOSk8IkFxdx6frGanYqISMIoZMnQWQsH33NGtyqegUjI2Sux7F6YdRN4fKNaTmcozB+2HOKpDVW8vbsRa+GCyTncunAC188rIj2gvRNFRGT0KGRJfHQcdvZMLH8MmvdDaj4s+AyU/TlkTRz1cmqau/jd+9U8taGKPQ0d+D0uls4qYPn8CVx+bj5+j9ZviYjIyFLIkviKRmH3y1D+n7DjD85o17nXw8V/CRMXj+pCeXCanW482MyzG2v4/aYaDreHSA94uH5uEcvnj+fCqbnarFpEREaEQpaMnOaDsP5nzuhW1xGYUOaErVk3gmv0R5LCkShv7W7k2Y3VrN1yiI5QhMIMPzeWjmf5/AnMnZChBfMiIhI3Clky8kIdzubU7zwCR/ZC9mS48IvOYvmU7ISU1BWK8NK2Op7dWMOr2+vpjVim5KVy43njuem88ZxTMLp3S4qIyNlHIUtGTzQC21bD2w87+yV6AjDnE7DwHii5YNSnEo9q6ezl+S21rPqghnf2OAvm54zP4KbzxnPjeeMZn5WSkLpEROTMppAliVH7gdNRftMTTs+tgjlO2Cq9A1KyElZWXWs3v9/kBK4PDjYDzh2KN84fzw3zishJHd07JkVE5MylkCWJ1dMOW56E8p9B7UbwpMDcW527EicsTNjoFsC+wx0890ENz35Qw676djwuw8Xn5HHDvHFcM3sc2QpcIiJyCgpZMnbUvO+Erc1PQm8HFM6DhXc7oWsU90s8kbWWyto2Vn1Qw+rNNRxs6sLjMlw0LZcb5hVxzZxxGuESEZGPUMiSsae7FTb/1rkz8dBmcHlhxrXOQvnp14DHn7DSrLVsqW5l9eZa1myu5UBTJ26X4eJpuVw/r4hrZheSm5a4+kREZOxQyJKxy1onZH2w0gldHfXO3Yhzb4PFX4LcaQkuz7K15njg2t/oBK7FU3NYNreIK2cWMEGL5kVEkpZClpwZImHY84oTuCpXQTQMs5fDBV+AkgvB5UpoedZaKmpbWbO5ljWbD7H3cAcA5xams2zuOG5UWwgRkaSjkCVnnrZD8O6PnSanPa2QORHmfgLm3Q6FcxK6WB6cwLW7oYNXttXzYmUdf9rX5DS+L0znsnPzuXR6PoumZGtrHxGRs5xClpy5etqcvlubn3S28rERyJ8F8251phRzpiS6QuB4W4gXK+oo399Eb8SS7vewdFYBy+YWcdmMfFJ8ClwiImcbhSw5O3Qchq2/gy1PwYF3nGPFi5zRrTm3QFpBYuuL6egJ887uRtZuPcQLlXU0d/aS4nVzxcx8rpk9jsvPzScrqDsVRUTOBgpZcvZpPuCErc1PQd1mMC6YcqkTtmbeCKm5ia4QgN5IlPf2NPH8llrWbq3jcHsPLgNlk3K4clYBV80qYFp+mvZTFBE5QylkydmtfptzZ+LWp6FpDxi3M7p1yf+G/BmJru6YaNTyQVUzL2+r56XKeipqWwGYmBPkypkFXDWrkAum5ODzJHaBv4iIDJxCliSHY+0gfu1s59PbBbM+DqV3wvSrE9p7qz81zV2xwFXHW7sbCYWjpPk9XDojjytnFnL5ufnkqR+XiMiYppAlyafjMLzzI9jwX9DZCP5MmH4VTFsK5yyF9HGJrvBDOkNh3t7VyEvb6nipsp76th6MgfklWVw1q5ArZxYwc1y6phVFRMYYhSxJXpFe2POaM5W48wWn2SkGJn/MmVKcfZPT/HQMOdoA9cXKOl7eVs+mqhYAJmSlcOXMAq6cVcBFU3MJeHW3oohIoilkiQBEo1C3Bbb93mkJ0bTb2c5n+jVOS4jp14A/PdFVfkR9a7czrbitnjd3HqarN0KK183HpuexdGYBV84soCAjkOgyRUSSkkKWyImsdTar3vykc5di+yFw+2DyJXDudc4jszjRVX5Ed2+Ed/Y08nKls5arpqUbgNLizGOL5+eMz9C0oojIKFHIEjmVaAQOvAs7nodta5wRLoBxpVB6B8y7A9ILE1tjP6y1bDvUxsuxrvMbDzZjLRRm+LlyZgFLZxay5Jw8NUEVERlBClkig3F4J2xfAxXPQvV6pyXEOUvhvBVw7vXgHZtTc4fbe3h1ewMvVdbx+o4GOkIR/B4XF0/LZWls8fx4bWYtIhJXww5ZxphlwL8BbuCn1trvn+S8W4EngUXW2nJjzGSgEtgeO+Vda+0XT/VZClkypjTscFpCfLAS2mqcuxRLLoDxC44/MooSXeVHhMJR/rS3iRcr63hpWx0Hm7oAmF2UwdJZzjqu84qzcLk0rSgiMhzDClnGGDewA7gaqALWASustRUnnJcOrAZ8wJf7hKzfW2vnDrRYhSwZk6IR2Puas61P9Qaor3T2UQRIG+d0ml90H+RNT2yd/XA2s27nxcp6Xq6sp3x/E1ELeWk+rji3gKWzCvjY9HzS/J5ElyoicsYZbsi6CPiOtfba2POvAVhr//6E8x4CXgD+Gvg/CllyVgt1Oo1Pa96H/W/B9uch2gtTL4dFn4UZ14F7bIaWIx0hXtvRwEvb6nl1ez1t3WF8bhcXTs1h6cwCls4qpCQnmOgyRUTOCMMNWbcBy6y1n409/wxwobX2y33OOR/4urX2VmPMq3w4ZG3FGQlrBb5hrX2jn8/4PPB5gIkTJy7cv3//oL+kSEK11zuNT8t/Bq1VkDHB2UsxbzrkzYDc6ZAzFTxja2Po3kiU8n1HeDnWBHXP4Q4AZhSmceXMQq6aVcCCidm4Na0oItKvEQ1ZxhgX8DJwj7V23wkhyw+kWWsbjTELgWeAOdba1pN9nkay5IwWCcPOP8KGx6H2A2irPf6acTsjXZf+NUy6KFEVntKehvZjeyuu29dEOGrJDnq5PDateOmMfDIC3kSXKSIyZozodKExJhPYDbTHLhkHNAE3WWvLT3ivV4kFsJN9nkKWnFV62py7FRt3OY1Q3/8VdB6GCWVQMNNZz1W8yNlb0TW2Wi20dPXyxs4GXqqs55Xt9TR39uJzu7hqdgG3LSzm0un5eNzazFpEkttwQ5YHZ7pvKVCNs/D9k9barSc5/1WOj2TlA03W2ogxZirwBjDPWtt0ss9TyJKzWqjTmVbc9BtorXG2+bFRyJwIZffAxIugYNaY2+onErW8f+AIv99Uy6oPamjqCJEV9LJ0ZiHXzink0hn52uZHRJJSPFo4XA88hNPC4TFr7YPGmO8B5dbaVSec+yrHQ9atwPeAXiAKfNta+9ypPkshS5JKpNfpyfWn/4B9fZYr5p4Ds26EWTdB0XxwjZ0Ro1A4yqvb6/nDlkO8WFlHa3eYFK+bS2fkcf28Iq6aVUiq7lQUkSShZqQiZ4LWGqjb6jz2vAp7X3faRPgzoWQRTLoYpi11OtGPkdDVG4ny3p4m1m49xB8rDlHX2kPA62LpzEIumZ7HRdNymZgT1DY/InLWUsgSORN1NjmL6A+8Awfeg4ZK53hqAYyb59ytWHQelP7ZmLhrMRq1rD9whOc+qOH5LYdoaOsBYHJukBtKi/h46XhmjktX4BKRs4pClsjZoL0edr8Mu1+Bw9uhcQ/0tED2FLjqO8704hhZPH+0Aepbuxp5sbKOt3c3EolaCtL9LJ6aG3vkMCUvVaFLRM5oClkiZyNrYddL8MI3ob4CjAuCec42P0XnwfjznW1/CueAO7FtFxrbe3ihoo539jTyzu5G6mOjXAXpfpbNHcet5xdTWpypwCUiZxyFLJGzWTTibPfTsM0Z7Wo+4HSi7252Xnf7nbB1/l0w7zbw+BNarrWWvYc7eHdPE2/uauDFynpC4SgTc4IsmJjFvAmZzJuQyZwJmdrqR0TGPIUskWRjLRzZ64St6g3OiFdDpbOea/o1EMh02kSMX+BseB3ISFipLV29rNlcy0uV9WypbuFQazcAxsD0gjSunl3IdXOLmDM+QyNdIjLmKGSJJDtrYc8r8O6PnT0Xe9ogFOsfbFxQciGct8LZ6DqBgQugoa2HLdUtbKpq4b29jby7p5GohYyAh+mF6Zw7Lp1Fk7NZPDWXosyUhNYqIqKQJSIfFeqAqnWw7y2oeNZZTO9JgXFzIf9cZ0F9ap6zzmvKpQkLX43tPbxUWc+m6mZ21LVTWdtKW3cYgIk5QRZPzeHCKbmcV5LJlLw07bMoIqNKIUtETs1aqF4Pm3/r9Olq2O50oz8qvQiu/wHM+njiaoyJRC2Vta28t7eJ9/Y08t7eJlq6egFI8bo5pyCNCVkpjM9KYUJ2ChOyAkzLT+OcgjRNN4pI3Clkicjg9XY5vboad8Larzt7L5YsBpcHulsgmA35M53mqHNuBn96QsqMRi0769vZUt3C5uoW9hzuoKa5i+ojXXT1Ro6dV5QZ4LIZ+Zw/MZvZ4zOYUZiOzzM2mrqKyJlLIUtEhifSC28/DFufBl+6s3C+o94Z8Qq1O13py/7cCVtZk5xF9QkeNbLW0tzZS3VzF1uqW3htRwNv7jp8bKrR6zZML0iPBa40JuWmMiUvlYk5Qe3DKCIDppAlIiPDWqgqh3d+BJWrnM2uwQliWRMhq8S5g/G8OyF7ckJLBWfUa19jB1trWtla00pFbSsVNS0cbg8dO8cYGJ+ZwqTcIJPzUpmSm+r8zAtSkhPE71EAE5HjFLJEZOQ1H4TajU6frqOPI/udRqlYmHwJnHsdTL0CCmZ9eKQr1AntdU4QS8AIWEtnL/saO9jX2MHewx3sb+xk72HneXNn77HzjgawyXlBsoI+MgIeCtIDzBmfwZwJmRRlBHBp4b1IUlHIEpHEaT4IH6yETb9x1ncBpI2DqZfDxMXOHY4VqyDUBqn5zkbYs5fDzBudPRm7mmHbasid5px/1KHN4AlA3vSRLb8zxL7GTvYdPhrAOtjf1ElLVy+tXWEaO3o4+p9Rj8tQkO6nMDPAuIwAhRkBxvX5vTDDz7jMAEGfmqyKnC0UskRkbGg+4Oy9uOcV2PMadDWBPwNm3wRF853Atfd1aKt1GqcWL4LdL0HYaVDKeZ+Ei/6Hsz5s02/Amwp3/hKmXfnRz7J2VEbFOkNhKmvbqKxtpaa5i0Ot3dS1dnOopZu61h7ae8IfuSY94GFcRoCCDD8ZAS+pfuf59MI0pualEfC6MAb8HjfZqT5SfW7dGSkyRilkicjYE406I1tZE8Gb8uHju1+CdT+Fmo1O24jSP4Ptz8PbP4Ro2NkqaPEXY53st8PyH0HudDi8w5myPPCuc3z+Crj6b8GfBluedu6SnHIJXPv3kJrrBLHDO5wRsayJIxLK2nvCscAVC1+t3dS1OD8b2pwQ1tYdpr6th0i0//8e+9wuirICFGenUJAeIMXnJuh1k5vmpzDDT06qD5/bhcftItXvJjPFS2aKlzS/R+FMZIQpZInI2aGuAravhnm3O+u3upph5Sdh/1vHz/EGYcJCSB8Hm590wlPhXOe6vBnQtNdprHreCtj5gtOEFZypyomLoexeZ90YQM0G2Pcm5M+CiRc6d1WeTvMBZypz4kUQzDn5eeEeZ71a0Xwwhp5whAPVhwhv+BXVRUvpTCmiOxShuStEY0eImuZu6puO0NHWwqFwGh09kQ+1qOiP22WOBa6M2M+s2M++j6DfTYrX7YQ3n4cUr5ugz03A4yLNHSYQTD0W1rp7I4QiUTICid10XGSsUMgSkbNXbxdseQoCWcc71btja572vwPPfAlaq+HyB+Di/+mMXK36S6guh4kXw9xPOOdWr3dGxjrqoWC2s/H20QAGgHHWf+XNcAJeT5uzIbc/3Rkxm3wJ/OlRePnvoLfT2a6oeJFzrtvntLWYtAQmXQTb/wCv/J0TyObeBjc+BB2H4dd3Oht9u/1w4RecwJeSBZEwlP8nvPcTZ4p10seg9A46pi6jLpzKkc4QveEIvsbttJJKncmlpauXYP0GZtU8TROZPBO4mapQGi1dvbR09dLV1clkaik2DbwfPYdGPhwg/YT4d++/sci1je9G7uO1wOV0hiJ0hpxgNyczxIPuR+lOKeDlwvvo8uXgMmCMIehzU+xpZk7TS4THL8Qz8QLSU3z4vW58bhd+rwu/x4XP7cKAEzaNGzInJKzfmshQKWSJSPLq7XKap6aPO34sGnX6e524VVC4xwls637qBKPSP4MZy5xgduAdZ4Tq8E44ss+5Nm0ctFZB1xFnfVhvh3P+hV9wAt7ul5zwFAk5jV0jPcc/a9w8mHwpvPdjJxh2NzvB7oZ/hl0vOjcLcMJ/n2dcB0WlTo2NuwADxWVOkNvzKnQ0OOdlTnRG3eo2O+00ejucKdHSO5y/RX0ltnEXJuqsF7PGRXvRRTRMvJ6acUtpj/pY8PZfUHD4XZpSp5HbsYv3s67hzZIv4MqeRFb3Aa55/8tk9jbgIko3fn5ulvMec9ltx7Ms/CpfcT9BuukCoNbm8FqklJ22mN12PE02nQ4CzDH7+Lz3eeaaPce+Yq0pYGXKnbwRvBqv14vP4yLFDWU973JR+x9pTylmy4wvkZGZQ8DrJkCINLoIZuWRkRp0Ru0C3uONZq11/vkc2eeE4t4Op+/b9GuOjzRGo/DKg84/pymXOSOa/rTjf/fWWicQFy8C1wg2sLXWeZzuMw7vhO5WKF54+vMqnnX+fewvvHY0AtbZPmsgWmvgqc/C5I/BZV8Fl9qZgEKWiMjICffAtt/DjrUw41qY84n+13b1dkPVn5y9IvNnwOxbnP+Z7n0DnroPfGnwyScg7xzn/PpK50aAnnZn4f+510PBTOc1a521ZzvWws4/OndwTrkUzlnq/M/3wNvO/xBL/8yZFm2rhdf+0Wkmm1nsjNQVzHJ+phc5NyJseRqadjsjSunjnGuW/7szNfvGP8Nr/wA2Apkl0NMKLi+sWOmEuT9+A3au/fCfZcqV1F/4AKHaClJ3Psf/a+/eY+QqzzuOf5+57u7sxXsxi+9eh0BKYwgGmqQFmippwA6J0yZNXTVNUBCkUqOUpiilQkpR/0lDk6aKlJSmbQIkaUMvWLEaEQFpRVo1uMXGxgbjG7ax13vxevFeZnfub/94z67Hy66NYM8ce+b3kUZ75p1jz/vMe86cZ973vOe0jzxPujD6uo9lpGkN25d+nAlrpTU3yDvHn2Ft7mVOJlZxJLGOlsoEq4tH6XajjNBJlzvDMEv4dul23hU7xAdiO2kxn7yOuxZOum76XQ8Vi7OSYVbaqdlkr9rR2Cq+1PkgZHr4TPbved/px6hYnJjzPXW5dA/5zArS+dM0ZU/4smU3kL31r0ktuZzM9m8Qe/4Rn9CufrdPwC5f73s6J4d979zkELR0Q3OX700dfskPV5fzvney72a48S4/i3ZgNzz+WZ88ty+H9hW+FzPdBq29vq1al8KOh2HfvwPOt+1tf+HXm2v/T+Dxu3xb9VwFv/19v93NOPAkbL0bSgW45Y/hvZ+DRNpfTqVSev0PkPGT8PDtPtmsFP3s4I0PwuH/8LfjSrb47a/vFliy1iewc/eD1475f79ktY8vvkizbMtFn0wWp3zyXP2DqgaUZImIXMwKU75XIJEO933ON+PSOX/rpBe3+mHTX/k8vPNjZ18/fdgfUI/+l7+5+KavQlff2ddfO+rPmRt+yd9u6R0fev17ZUd8EjF9xvckZnp8b151z41zPmn92Vd9gtDc5YcRr9niD6CDu6lsu4fY0AuUmzoZX/chJtquoJwdxWVHSGQHaM72Q6XEeNNyxtLLGYz18mplKQOuC0tlWO4GuKP/AQYSK3kmeTOfmnqER8sf5MvFLVwfO8gGO8gKG2G5jTBBCzsqV5Inyb2Jf6aZPDlStDHNU+5G2mI5ruUAGfwM2ApGbG4PZKBicaaal1GONYEr05E9wljLWo73/hpXH/s+rrmb2DWfwCYHfFKTG4f8GEwM+l428HdXePfd/nP676/7JPmqjT6ZS7f5BG7sBDz3Xd/r+cufhyf+xCfqN97pE5zRI/4Cwr3roXON/7zblvsh7nGfUNK51t8yq6vPJ0Tb/9YnjZ983A+j//jesz2zy671vbBDe88GG0/79796MyzfADu+63tgZy5YHEv4RH/F9f6cx+ZOSLX4Hxev/tz3Hna/DbrWwdRp34s8Nep/yKz/uK/TxKAf5n/2WzB2/Ox7X36NT7SSLT6+X//z+bf5RaIkS0RE6ke5BKf2+WQu/iZPwD/0U38OP9wFqAAACVxJREFUXLkAV22i8lvfI1eBqUKZ6UKZXNGffzZdDB6FMpWJIX5h79ew4hQ/X3UnJ1LrmC6UyefztGWP0ZM9wGW5I5yik/2s4USpg0T+DOnCawyWOzjklpMnNVuF98We588Sj9IXG+Kp8vV8sXgXZ6yd9qaZyQoJOpqTpGOOjunjdOVPMtp9Hct6e1nR2czKqZe4ds+XyUweJVkYm/1/HUblmi3EP/x1P3N3rB+2fhaO/Y/vjQS4/g7fC5Zs9snzsw/5RKf7CjBgcK9Pms686j+jVBt88l/PXqtucI+fOHLlrdD7i75sYhCOb/cJ4tgJOPKMXw/8cPqNwaSS8X4YfcXPHu7f6RPJWeaTryVr/Dqjr/ieusvXQyoDB5+G0pyeydXvhZv+yPfS7n/CXwYmN+Z7tjpWwu9tfXPbyBukJEtERGSug0/Dvh/5ZCOVCfWtcsUyE7kS04Uy8biRiBkxMxKVAm5gNweS7+DgqSzD47ngQrfF2UkKpYqjORknGY9x8sw0r45OUZpzuY84ZTLkyJMkTxIwUvEYLek47U1J2poSdKRjrEhN0pmqUGpfQ3tzgkwqQSrhJyKkkzFS8TiZdJye1jRL29I0J41UbpRUUwux5jcwu3au04d9InXF++efbVup+MkcuTHfc9nZd+7wZ6Vybk9nfhIO/MQnUG3Lfc9c9TBoBJRkiYiI1IliucLIZN7P9syXyRZKTBVKZPPlc/8WymSD67CNTxcZzxWrlkvzXih3ITGDzpYUXZkUiXgM5xzxmNHZkqIzk6KrJUlnJkVnS4q2pgSZdIK2dILWOcvNyfq7sO75kizd20FEROQSkozHWNbRfOEVL6BccUwXy+SDa5/lixXypQoTuSIjk3lGJgvkimWKZcdUocTpbIHRyQKliiNmUKo4zkwV6D8zzWi2wNh08YLvGTNmk65MkHi1pqsewfP2piRdmRTdrSla0wnSCX8dt6VtadqbLp2L7CrJEhERaUDxmM0mN4uhWK4wNl2c7T2bzJfI5kuzdzWYb3nm+eBYzj/PlZgslDjfIFs6EZu9o0FbU4Ke1jSXtaeDXjR/LltbMETak0mzfuWbGOZcJEqyRERE5C1LxmP0tKbpaX1rs2Sdc0zkS4xO+rsdTBVK5IoVsvkSI5N5hifyjE0VmSz4oc+TYzl2nzjDa1PF192a6orLWnn6C7/6lurzVijJEhERkYuGmdHe5C8qu7bnjU9IcM4Pf07kSkzk/HlnUVOSJSIiIpc8f0unBC2pBL3tTVFXB4AQ7w8gIiIi0riUZImIiIiEQEmWiIiISAiUZImIiIiEQEmWiIiISAiUZImIiIiEQEmWiIiISAiUZImIiIiEQEmWiIiISAiUZImIiIiEQEmWiIiISAiUZImIiIiEQEmWiIiISAiUZImIiIiEQEmWiIiISAjMORd1Hc5hZqeAYzV4qx5gpAbvc7Fq5PgbOXZQ/I0cfyPHDopf8YcT/xrn3NL5XrjokqxaMbPnnHM3RF2PqDRy/I0cOyj+Ro6/kWMHxa/4ax+/hgtFREREQqAkS0RERCQEjZxkfTvqCkSskeNv5NhB8Tdy/I0cOyh+xV9jDXtOloiIiEiYGrknS0RERCQ0SrJEREREQtBwSZaZ3WZm+83skJndF3V9wmZmq8zsP83sJTN70cz+MCh/wMz6zWxX8NgUdV3DYmZHzWxPEOdzQVmXmT1lZgeDv51R13OxmdlVVe27y8zGzeyeem57M/uOmQ2b2d6qsnnb2rxvBN8FL5jZhuhqvjgWiP8vzezlIMatZrYkKF9rZtNV28FD0dV8cSwQ/4Lbu5n9adD++83s1mhqvTgWiP2xqriPmtmuoLwe236hY120+79zrmEeQBw4DKwDUsBu4Oqo6xVyzMuADcFyG3AAuBp4ALg36vrV6DM4CvTMKXsQuC9Yvg/4StT1DPkziAODwJp6bnvgFmADsPdCbQ1sAp4ADHgPsD3q+ocU/weBRLD8lar411avVw+PBeKfd3sPvgd3A2mgLzg2xKOOYTFjn/P614Av1XHbL3Ssi3T/b7SerF8CDjnnXnHOFYAfApsjrlOonHMDzrmdwfIEsA9YEW2tLgqbgUeC5UeAj0ZYl1p4P3DYOVeLuylExjn3M2B0TvFCbb0ZeNR5zwJLzGxZbWoajvnid8496ZwrBU+fBVbWvGI1skD7L2Qz8EPnXN45dwQ4hD9GXJLOF7uZGfAJ4J9qWqkaOs+xLtL9v9GSrBXA8arnJ2ighMPM1gLXAduDos8F3aTfqcfhsioOeNLMdpjZ3UFZr3NuIFgeBHqjqVrNbOHcL9hGaXtYuK0b8fvgM/hf7zP6zOx5M3vGzG6OqlI1MN/23kjtfzMw5Jw7WFVWt20/51gX6f7faElWwzKzVuDfgHucc+PA3wBvA94FDOC7kuvVTc65DcBG4A/M7JbqF53vO67ba5mYWQr4CPAvQVEjtf056r2tz8fM7gdKwA+CogFgtXPuOuALwD+aWXtU9QtRw27vVX6Hc39k1W3bz3OsmxXF/t9oSVY/sKrq+cqgrK6ZWRK/0f3AOfc4gHNuyDlXds5VgL/jEu4mvxDnXH/wdxjYio91aKZrOPg7HF0NQ7cR2OmcG4LGavvAQm3dMN8HZnYHcDvwu8GBhmCY7HSwvAN/TtKVkVUyJOfZ3hui/c0sAfwm8NhMWb22/XzHOiLe/xstyfo/4O1m1hf8ut8CbIu4TqEKxuL/AdjnnPurqvLqseffAPbO/bf1wMwyZtY2s4w/CXgvvt0/Haz2aeBH0dSwJs75FdsobV9lobbeBnwqmGX0HmCsalihbpjZbcAXgY8456aqypeaWTxYXge8HXglmlqG5zzb+zZgi5mlzawPH///1rp+NfAB4GXn3ImZgnps+4WOdUS9/0c9I6DWD/yMggP4zP3+qOtTg3hvwnePvgDsCh6bgO8Be4LybcCyqOsaUvzr8DOIdgMvzrQ50A38FDgIPA10RV3XkOLPAKeBjqqyum17fDI5ABTx51jcuVBb42cVfTP4LtgD3BB1/UOK/xD+3JOZ/f+hYN2PBfvELmAn8OGo6x9S/Atu78D9QfvvBzZGXf/Fjj0ofxj4/Tnr1mPbL3Ssi3T/1211RERERELQaMOFIiIiIjWhJEtEREQkBEqyREREREKgJEtEREQkBEqyREREREKgJEtEREQkBEqyRERERELw/yN481shh9kJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vizualiser(logs,'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbVhVb4iiTEf"
   },
   "source": [
    "# CallBacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aM3RPQWfiTCW"
   },
   "outputs": [],
   "source": [
    "# 1. Conditional callback\n",
    "# 2. EarlyStoppping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "yhSrhr6HiTAV"
   },
   "outputs": [],
   "source": [
    "class ConditionalCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch,logs = {}):\n",
    "    if (logs.get('accuracy')>=0.8) & (logs.get('val_accuracy')>=0.8):\n",
    "      print()\n",
    "      print('Condition satisfied so stopping training !')\n",
    "      print()\n",
    "      self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "VzPRR4D_iS-T"
   },
   "outputs": [],
   "source": [
    "conditional_callback = ConditionalCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "baJnua2-iS8N"
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------Model Building\n",
    "# Initializingthe Sequantial container\n",
    "model1 = tf.keras.Sequential()\n",
    "\n",
    "# Adding layers\n",
    "# ---------Adding the input layer\n",
    "model1.add(tf.keras.layers.Input(shape = (13,)))\n",
    "\n",
    "# ---------Adding the 1st hidden layer\n",
    "model1.add(tf.keras.layers.Dense(units = 6, \n",
    "                                activation = 'relu', \n",
    "                                kernel_initializer = 'he_normal'))\n",
    "# ---------Adding the 2nd hidden layer\n",
    "model1.add(tf.keras.layers.Dense(units = 8, \n",
    "                                activation = 'sigmoid', \n",
    "                                kernel_initializer = 'glorot_normal'))\n",
    "\n",
    "# ---------Adding the output layer\n",
    "model1.add(tf.keras.layers.Dense(units = 1, \n",
    "                                activation = 'sigmoid', \n",
    "                                kernel_initializer = 'glorot_normal'))\n",
    "# -----------------------------------------------Model Building\n",
    "\n",
    "# -----------------------------------------------Model Compilation\n",
    "model1.compile(optimizer = 'Adam',\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['accuracy','Precision','Recall'])\n",
    "# -----------------------------------------------Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5yA5f0wAiS5x",
    "outputId": "15efcf82-25af-4af2-aa13-e6c47ae823d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "16/16 [==============================] - 1s 27ms/step - loss: 0.7585 - accuracy: 0.2069 - precision: 0.2042 - recall: 0.9860 - val_loss: 0.7310 - val_accuracy: 0.2125 - val_precision: 0.1832 - val_recall: 0.8724\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.7129 - accuracy: 0.3319 - precision: 0.1800 - recall: 0.6328 - val_loss: 0.6874 - val_accuracy: 0.5695 - val_precision: 0.1387 - val_recall: 0.2296\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6727 - accuracy: 0.6981 - precision: 0.1375 - recall: 0.0888 - val_loss: 0.6495 - val_accuracy: 0.8000 - val_precision: 0.1000 - val_recall: 0.0026\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6381 - accuracy: 0.7943 - precision: 0.3333 - recall: 6.0790e-04 - val_loss: 0.6166 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6083 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5885 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5833 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5656 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5634 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5474 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5478 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5334 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5362 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5228 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5275 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5152 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5214 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5093 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5169 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5051 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5137 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5019 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5113 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4997 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5097 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4980 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5085 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4967 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5075 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4956 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5068 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4947 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5062 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4940 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5056 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4933 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5051 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4927 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5046 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4921 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5041 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4915 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5036 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4909 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5031 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4903 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5025 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4897 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5020 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4890 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5014 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4883 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5007 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4876 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5001 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4868 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4994 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4861 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4987 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4853 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4979 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4844 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4972 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4836 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4965 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4829 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4958 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4821 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4951 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4812 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4944 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4804 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4937 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4795 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4929 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4787 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4921 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4779 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4913 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4770 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4905 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4761 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4897 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4751 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4888 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4741 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4880 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4732 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4871 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4722 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4862 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4712 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4853 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4703 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4845 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4693 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4836 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4683 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4828 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4673 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4819 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4665 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4811 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4656 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4803 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4647 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4795 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4640 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4787 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4631 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4780 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4623 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4772 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4614 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4765 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4608 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4758 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4600 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4751 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4593 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4744 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4586 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4737 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4579 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4730 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4571 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4724 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4565 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4717 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4559 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4711 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4551 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4704 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4544 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4698 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4539 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4691 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4532 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4685 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4527 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4519 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4673 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4511 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4509 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4504 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4655 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4495 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4649 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4490 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4643 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4483 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4637 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4478 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4631 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4474 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4626 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4472 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4619 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4461 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4614 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4461 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4608 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4451 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4602 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4449 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4596 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4441 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4590 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4436 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4584 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4430 - val_accuracy: 0.8045 - val_precision: 1.0000 - val_recall: 0.0026\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4577 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4430 - val_accuracy: 0.8055 - val_precision: 1.0000 - val_recall: 0.0077\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4572 - accuracy: 0.7935 - precision: 0.1111 - recall: 6.0790e-04 - val_loss: 0.4425 - val_accuracy: 0.8075 - val_precision: 1.0000 - val_recall: 0.0179\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4566 - accuracy: 0.7937 - precision: 0.2222 - recall: 0.0012 - val_loss: 0.4412 - val_accuracy: 0.8070 - val_precision: 1.0000 - val_recall: 0.0153\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4559 - accuracy: 0.7946 - precision: 0.5556 - recall: 0.0061 - val_loss: 0.4411 - val_accuracy: 0.8100 - val_precision: 0.9286 - val_recall: 0.0332\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4553 - accuracy: 0.7956 - precision: 0.6389 - recall: 0.0140 - val_loss: 0.4409 - val_accuracy: 0.8120 - val_precision: 0.9444 - val_recall: 0.0434\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4546 - accuracy: 0.7960 - precision: 0.6444 - recall: 0.0176 - val_loss: 0.4400 - val_accuracy: 0.8120 - val_precision: 0.8636 - val_recall: 0.0485\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4541 - accuracy: 0.7962 - precision: 0.6531 - recall: 0.0195 - val_loss: 0.4391 - val_accuracy: 0.8125 - val_precision: 0.8148 - val_recall: 0.0561\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4535 - accuracy: 0.7985 - precision: 0.6701 - recall: 0.0395 - val_loss: 0.4394 - val_accuracy: 0.8170 - val_precision: 0.7826 - val_recall: 0.0918\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4528 - accuracy: 0.7995 - precision: 0.6990 - recall: 0.0438 - val_loss: 0.4381 - val_accuracy: 0.8160 - val_precision: 0.7609 - val_recall: 0.0893\n",
      "Epoch 99/200\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.4510 - accuracy: 0.7995 - precision: 0.6632 - recall: 0.0429\n",
      "Condition satisfied so stopping training !\n",
      "\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4520 - accuracy: 0.8000 - precision: 0.6991 - recall: 0.0480 - val_loss: 0.4380 - val_accuracy: 0.8130 - val_precision: 0.6500 - val_recall: 0.0995\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "logs1 = model1.fit(x = tr_x,\n",
    "                 y = tr_y,\n",
    "                 batch_size = 512,\n",
    "                 epochs = 200,\n",
    "                 validation_data = (ts_x, ts_y),\n",
    "                 use_multiprocessing = True,\n",
    "                 workers = 9,\n",
    "                 callbacks = [conditional_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s7ss3rEqkSst",
    "outputId": "1c10ab01-9abe-4337-e20a-337d4a2d7515"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs1.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "NA7diabakoim"
   },
   "outputs": [],
   "source": [
    "# Early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "mpt4GsZuk87N"
   },
   "outputs": [],
   "source": [
    "early_stopper = EarlyStopping(monitor = 'loss', patience = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "wofJuA7Ulcbd"
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------Model Building\n",
    "# Initializingthe Sequantial container\n",
    "model2 = tf.keras.Sequential()\n",
    "\n",
    "# Adding layers\n",
    "# ---------Adding the input layer\n",
    "model2.add(tf.keras.layers.Input(shape = (13,)))\n",
    "\n",
    "# ---------Adding the 1st hidden layer\n",
    "model2.add(tf.keras.layers.Dense(units = 6, \n",
    "                                activation = 'relu', \n",
    "                                kernel_initializer = 'he_normal'))\n",
    "# ---------Adding the 2nd hidden layer\n",
    "model2.add(tf.keras.layers.Dense(units = 8, \n",
    "                                activation = 'sigmoid', \n",
    "                                kernel_initializer = 'glorot_normal'))\n",
    "\n",
    "# ---------Adding the output layer\n",
    "model2.add(tf.keras.layers.Dense(units = 1, \n",
    "                                activation = 'sigmoid', \n",
    "                                kernel_initializer = 'glorot_normal'))\n",
    "# -----------------------------------------------Model Building\n",
    "\n",
    "# -----------------------------------------------Model Compilation\n",
    "model2.compile(optimizer = 'Adam',\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['accuracy','Precision','Recall'])\n",
    "# -----------------------------------------------Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p7IosVOxljyj",
    "outputId": "f0d2058d-9cf1-4828-cc69-457a2802d1bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "16/16 [==============================] - 1s 26ms/step - loss: 0.6021 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5855 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5786 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5630 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5588 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5440 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5423 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5286 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5294 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5162 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5194 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5067 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5121 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4997 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5069 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4947 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5033 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4913 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5010 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4887 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4992 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4869 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4981 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4854 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4969 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4841 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4960 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4831 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4951 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4820 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4942 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4810 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4934 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4801 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4925 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4791 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4916 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4780 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4907 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4770 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4898 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4759 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4889 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4750 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4879 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4738 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4870 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4727 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4860 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4714 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4849 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4702 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4838 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4691 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4828 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4680 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4817 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4669 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4806 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4656 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4796 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4645 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4785 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4633 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4775 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4623 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4765 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4612 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4756 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4604 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4746 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4594 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4736 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4585 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4576 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4719 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4564 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4710 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4560 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4550 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4540 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4533 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4526 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4518 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4512 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4504 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4643 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4500 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4636 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4492 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4628 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4483 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4620 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4482 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4612 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4471 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4605 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4465 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4597 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4461 - val_accuracy: 0.8040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4589 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4454 - val_accuracy: 0.8045 - val_precision: 1.0000 - val_recall: 0.0026\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7943 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4448 - val_accuracy: 0.8040 - val_precision: 0.5000 - val_recall: 0.0026\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4574 - accuracy: 0.7944 - precision: 0.5000 - recall: 0.0018 - val_loss: 0.4441 - val_accuracy: 0.8035 - val_precision: 0.4000 - val_recall: 0.0051\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4569 - accuracy: 0.7951 - precision: 0.6875 - recall: 0.0067 - val_loss: 0.4443 - val_accuracy: 0.8030 - val_precision: 0.4286 - val_recall: 0.0153\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4559 - accuracy: 0.7956 - precision: 0.7500 - recall: 0.0091 - val_loss: 0.4426 - val_accuracy: 0.8035 - val_precision: 0.4667 - val_recall: 0.0179\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4551 - accuracy: 0.7962 - precision: 0.7586 - recall: 0.0134 - val_loss: 0.4424 - val_accuracy: 0.8045 - val_precision: 0.5217 - val_recall: 0.0306\n",
      "Epoch 61/200\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.4539 - accuracy: 0.7991 - precision: 0.8276 - recall: 0.0325\n",
      "Condition satisfied so stopping training !\n",
      "\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4545 - accuracy: 0.8001 - precision: 0.8382 - recall: 0.0347 - val_loss: 0.4421 - val_accuracy: 0.8065 - val_precision: 0.5806 - val_recall: 0.0459\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "logs2 = model2.fit(x = tr_x,\n",
    "                 y = tr_y,\n",
    "                 batch_size = 512,\n",
    "                 epochs = 200,\n",
    "                 validation_data = (ts_x, ts_y),\n",
    "                 use_multiprocessing = True,\n",
    "                 workers = 9,\n",
    "                 callbacks = [conditional_callback, early_stopper])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHLPEOfOlsU_"
   },
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zkxiS_VRl7xR",
    "outputId": "7083c19c-096f-49a4-fef1-632a9e980227"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.1.3-py3-none-any.whl (135 kB)\n",
      "\u001b[K     |████████████████████████████████| 135 kB 14.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.21.6)\n",
      "Collecting kt-legacy\n",
      "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (7.9.0)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.8.0)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
      "Collecting jedi>=0.10\n",
      "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 56.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.0.10)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->keras-tuner) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (0.2.5)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (1.15.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.9)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2022.6.15)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.48.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.4.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.2.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (4.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.8.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.0)\n",
      "Installing collected packages: jedi, kt-legacy, keras-tuner\n",
      "Successfully installed jedi-0.18.1 keras-tuner-1.1.3 kt-legacy-1.0.4\n"
     ]
    }
   ],
   "source": [
    "# keras-tuner\n",
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "CDE3_811l7vI"
   },
   "outputs": [],
   "source": [
    "from keras_tuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3raO8zQYl7su"
   },
   "outputs": [],
   "source": [
    "# RandomSearch : 1. hypermodel > function that is building and compiling the model for you with an hyperparameter instance\n",
    "#                2. objective function > The function to perform the tuning on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UP-boavAoFFp"
   },
   "source": [
    "1. `hyperparameter.Coice('statement describing this particular paramter',[list of elements])`\n",
    "- ex. hyperparameter.Choice('activation fuunction for first hidden layer',['relu','elu','sigmoid'])\n",
    "2. `hyperparameter.Int('statement describing this particular paramter', min_value, max_value, step)`\n",
    "- ex. hyperparamter.Int('Number of neurons in hidden layer # 1', min_value = 2, max_value = 10, step = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "b80jVFr2l7qP"
   },
   "outputs": [],
   "source": [
    "def hypermodel(hyperparameter):\n",
    "  # Instantiating the model\n",
    "  model = tf.keras.Sequential()\n",
    "  \n",
    "  # Adding the input layer\n",
    "  model.add(tf.keras.layers.Input(shape = (13,)))\n",
    "\n",
    "  # Adding the hidden layers\n",
    "  for i in range(hyperparameter.Int('Number of Optimal hidden layers',min_value = 1, max_value = 4)):\n",
    "    model.add(tf.keras.layers.Dense(units = hyperparameter.Int(f'Number of neurons in hidden layer # {i}',min_value = 2, max_value = 10),\n",
    "                                    activation = hyperparameter.Choice(f'Activation function in hidden layer # {i}',['relu','elu','sigmoid']),\n",
    "                                    kernel_initializer = hyperparameter.Choice(f'Kernel Initializer for layer # {i}', ['he_normal',\n",
    "                                                                                                                      'he_uniform',\n",
    "                                                                                                                      'glorot_normal',\n",
    "                                                                                                                      'glorot_uniform'])))\n",
    "  \n",
    "  # Adding the output layer\n",
    "  model.add(tf.keras.layers.Dense(units = 1,\n",
    "                                  activation = 'sigmoid',\n",
    "                                  kernel_initializer = hyperparameter.Choice(f'Kernel Initializer for layer # {i}', ['he_normal',\n",
    "                                                                                                                    'he_uniform',\n",
    "                                                                                                                    'glorot_normal',\n",
    "                                                                                                                    'glorot_uniform'])))\n",
    "  \n",
    "  # Compiling the model\n",
    "  model.compile(optimizer = hyperparameter.Choice('Optimization function',['Adam','rmsprop']),\n",
    "                loss = 'binary_crossentropy',\n",
    "                metrics = ['accuracy','Precision','Recall'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "cYTF2p0Nl7n0"
   },
   "outputs": [],
   "source": [
    "# Creating the tuner object\n",
    "tuner_object = RandomSearch(hypermodel = hypermodel,\n",
    "                            objective = 'accuracy',\n",
    "                            max_trials = 4,\n",
    "                            seed = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T9SIth2tl7la",
    "outputId": "2169f1fa-55be-4a3b-df1f-2355c1d2aa3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 Complete [00h 00m 02s]\n",
      "accuracy: 0.7943750023841858\n",
      "\n",
      "Best accuracy So Far: 0.7943750023841858\n",
      "Total elapsed time: 00h 00m 09s\n"
     ]
    }
   ],
   "source": [
    "# Tuning\n",
    "tuner_object.search(tr_x, tr_y, epochs = 10, batch_size = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HyY9GzmjsCih",
    "outputId": "b1b6f96d-1d26-4d3a-9143-ce0d6226a7a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ./untitled_project\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x7f224a333910>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Number of Optimal hidden layers: 2\n",
      "Number of neurons in hidden layer # 0: 5\n",
      "Activation function in hidden layer # 0: relu\n",
      "Kernel Initializer for layer # 0: he_normal\n",
      "Optimization function: rmsprop\n",
      "Number of neurons in hidden layer # 1: 2\n",
      "Activation function in hidden layer # 1: relu\n",
      "Kernel Initializer for layer # 1: he_normal\n",
      "Score: 0.7943750023841858\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Number of Optimal hidden layers: 3\n",
      "Number of neurons in hidden layer # 0: 9\n",
      "Activation function in hidden layer # 0: elu\n",
      "Kernel Initializer for layer # 0: he_normal\n",
      "Optimization function: rmsprop\n",
      "Number of neurons in hidden layer # 1: 9\n",
      "Activation function in hidden layer # 1: elu\n",
      "Kernel Initializer for layer # 1: glorot_normal\n",
      "Number of neurons in hidden layer # 2: 2\n",
      "Activation function in hidden layer # 2: relu\n",
      "Kernel Initializer for layer # 2: he_normal\n",
      "Score: 0.7943750023841858\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Number of Optimal hidden layers: 3\n",
      "Number of neurons in hidden layer # 0: 9\n",
      "Activation function in hidden layer # 0: relu\n",
      "Kernel Initializer for layer # 0: glorot_normal\n",
      "Optimization function: rmsprop\n",
      "Number of neurons in hidden layer # 1: 3\n",
      "Activation function in hidden layer # 1: elu\n",
      "Kernel Initializer for layer # 1: glorot_normal\n",
      "Number of neurons in hidden layer # 2: 4\n",
      "Activation function in hidden layer # 2: relu\n",
      "Kernel Initializer for layer # 2: he_uniform\n",
      "Score: 0.7943750023841858\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Number of Optimal hidden layers: 2\n",
      "Number of neurons in hidden layer # 0: 3\n",
      "Activation function in hidden layer # 0: relu\n",
      "Kernel Initializer for layer # 0: he_normal\n",
      "Optimization function: rmsprop\n",
      "Number of neurons in hidden layer # 1: 9\n",
      "Activation function in hidden layer # 1: sigmoid\n",
      "Kernel Initializer for layer # 1: he_uniform\n",
      "Number of neurons in hidden layer # 2: 5\n",
      "Activation function in hidden layer # 2: relu\n",
      "Kernel Initializer for layer # 2: glorot_normal\n",
      "Score: 0.7943750023841858\n"
     ]
    }
   ],
   "source": [
    "# Summarizing the models\n",
    "tuner_object.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7bIfQhiksSQ-",
    "outputId": "c239969b-8441-417a-d725-0e709a29b9d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.sequential.Sequential at 0x7f224a470110>,\n",
       " <keras.engine.sequential.Sequential at 0x7f224a5e7190>,\n",
       " <keras.engine.sequential.Sequential at 0x7f2232042710>,\n",
       " <keras.engine.sequential.Sequential at 0x7f2223e7c050>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = tuner_object.get_best_models(5)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vc-Q1UhWs4R1",
    "outputId": "4080443f-abd4-414b-8e34-9d2986d5d2d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 5)                 70        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 12        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85\n",
      "Trainable params: 85\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model = models[0]\n",
    "best_model.summary()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
